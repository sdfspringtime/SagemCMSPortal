[2022-11-16 12:01:30,372] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-11-16 12:01:30,385] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=C:\Users\1s0\Desktop\kafka_2.12-3.2.1/logs, -Dlog4j.configuration=file:C:\Users\1s0\Desktop\kafka_2.12-3.2.1/config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_333, 25.333-b02
	jvm.classpath = C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\activation-1.1.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\argparse4j-0.7.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\audience-annotations-0.5.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\commons-cli-1.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\commons-lang3-3.8.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-api-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-basic-auth-extension-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-file-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-json-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-mirror-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-mirror-client-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-runtime-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-transforms-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\hk2-api-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\hk2-locator-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\hk2-utils-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-annotations-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-core-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-databind-2.12.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-dataformat-csv-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-datatype-jdk8-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-jaxrs-base-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-jaxrs-json-provider-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-module-jaxb-annotations-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-module-scala_2.12-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.activation-api-1.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.inject-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.validation-api-2.0.2.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\javassist-3.27.0-GA.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\javax.servlet-api-3.1.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jaxb-api-2.3.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-client-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-common-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-container-servlet-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-container-servlet-core-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-hk2-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-server-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-client-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-continuation-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-http-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-io-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-security-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-server-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-servlet-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-servlets-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-util-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-util-ajax-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jline-3.21.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jopt-simple-5.0.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jose4j-0.7.9.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-clients-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-log4j-appender-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-metadata-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-raft-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-server-common-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-shell-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-storage-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-storage-api-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-examples-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-scala_2.12-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-test-utils-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-tools-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka_2.12-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\lz4-java-1.8.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\maven-artifact-3.8.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\metrics-core-2.2.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\metrics-core-4.1.12.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\MySqlConnector.class;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-buffer-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-codec-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-common-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-handler-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-resolver-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-tcnative-classes-2.0.46.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-classes-epoll-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-native-epoll-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-native-unix-common-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\osgi-resource-locator-1.0.3.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\paranamer-2.8.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\plexus-utils-3.3.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\reflections-0.9.12.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\reload4j-1.2.19.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\rocksdbjni-6.29.4.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-collection-compat_2.12-2.6.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-java8-compat_2.12-1.0.2.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-library-2.12.15.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-logging_2.12-3.9.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-reflect-2.12.15.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\slf4j-api-1.7.36.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\slf4j-reload4j-1.7.36.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\snappy-java-1.1.8.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\trogdor-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\zookeeper-3.6.3.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\zookeeper-jute-3.6.3.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\zstd-jni-1.5.2-1.jar
	os.spec = Windows 10, amd64, 10.0
	os.vcpus = 4
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-11-16 12:01:30,526] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-11-16 12:01:30,583] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\bin (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:30,636] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/bin/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:30,637] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:30,638] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:30,639] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:30,642] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\config (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:30,647] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/config/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:30,648] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\debezium (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:31,823] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/debezium/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:31,823] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:31,825] INFO Added plugin 'io.debezium.converters.ByteBufferConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:31,828] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:31,830] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:31,831] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:31,831] INFO Added plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:31,833] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:31,834] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:31,862] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:31,888] WARN Plugin path contains both java archives and class files. Returning only the archives (org.apache.kafka.connect.runtime.isolation.PluginUtils:294)
[2022-11-16 12:01:34,619] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/libs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:34,620] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,621] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,621] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,624] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,625] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,626] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,626] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,627] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,628] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,628] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,629] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,631] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,634] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,635] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,636] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,637] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,638] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,638] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,639] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,640] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,641] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,642] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,642] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,643] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,643] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,644] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,645] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,646] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,650] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,651] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,651] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,652] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,653] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,654] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,654] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,655] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,655] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,656] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,657] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,657] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,658] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,659] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,660] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,660] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,661] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,662] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,665] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,666] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,667] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,668] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,668] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,669] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:01:34,670] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\licenses (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:34,673] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/licenses/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:34,675] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\logs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:34,684] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/logs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:34,688] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\serverdata (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:34,692] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/serverdata/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:34,695] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\site-docs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:34,698] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/site-docs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:34,699] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\tmp (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:34,701] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/tmp/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:34,702] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\zookeeper-data (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:01:34,706] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/zookeeper-data/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:36,403] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:01:36,411] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,412] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,413] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,414] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,415] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,415] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,416] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,417] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,419] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,420] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,422] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,422] INFO Added aliases 'ByteBufferConverter' and 'ByteBuffer' to plugin 'io.debezium.converters.ByteBufferConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,423] INFO Added aliases 'CloudEventsConverter' and 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,424] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,425] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,426] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,427] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,427] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,428] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,429] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,430] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,431] INFO Added aliases 'ByteBufferConverter' and 'ByteBuffer' to plugin 'io.debezium.converters.ByteBufferConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,431] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,435] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,436] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,437] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,438] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,439] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,439] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,441] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,442] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,443] INFO Added alias 'ReadToInsertEvent' to plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,444] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,444] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,445] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,446] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,448] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,452] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,453] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,454] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,455] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,456] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,457] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,458] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,459] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,460] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,461] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:01:36,462] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,462] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,466] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:01:36,501] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = All
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = mpconnect.offsets
	plugin.path = []
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:376)
[2022-11-16 12:01:36,502] WARN The worker has been configured with one or more internal converter properties ([internal.key.converter, schemas.enable, internal.value.converter, schemas.enable]). Support for these properties was deprecated in version 2.0 and removed in version 3.0, and specifying them will have no effect. Instead, an instance of the JsonConverter with schemas.enable set to false will be used. For more information, please visit http://kafka.apache.org/documentation/#upgrade and consult the upgrade notesfor the 3.0 release. (org.apache.kafka.connect.runtime.WorkerConfig:316)
[2022-11-16 12:01:36,509] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:51)
[2022-11-16 12:01:36,514] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-16 12:01:36,664] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,666] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,670] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,671] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,672] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,673] WARN The configuration 'file' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,673] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,675] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,675] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,676] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,677] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,679] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:36,681] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:01:36,682] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:01:36,683] INFO Kafka startTimeMs: 1668596496680 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:01:37,424] INFO Kafka cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.connect.util.ConnectUtils:67)
[2022-11-16 12:01:37,429] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:01:37,443] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:01:37,446] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:01:37,447] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:01:37,469] INFO Logging initialized @8261ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-11-16 12:01:37,575] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:117)
[2022-11-16 12:01:37,576] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:188)
[2022-11-16 12:01:37,599] INFO jetty-9.4.44.v20210927; built: 2021-09-27T23:02:44.612Z; git: 8da83308eeca865e495e53ef315a249d63ba9332; jvm 1.8.0_333-b02 (org.eclipse.jetty.server.Server:375)
[2022-11-16 12:01:37,653] INFO Started http_8083@4defd42{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-11-16 12:01:37,654] INFO Started @8446ms (org.eclipse.jetty.server.Server:415)
[2022-11-16 12:01:37,705] INFO Advertised URI: http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:355)
[2022-11-16 12:01:37,706] INFO REST server listening at http://192.168.31.41:8083/, advertising URL http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2022-11-16 12:01:37,709] INFO Advertised URI: http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:355)
[2022-11-16 12:01:37,710] INFO REST admin endpoints at http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-11-16 12:01:37,711] INFO Advertised URI: http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:355)
[2022-11-16 12:01:37,712] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2022-11-16 12:01:37,732] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:51)
[2022-11-16 12:01:37,734] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-16 12:01:37,750] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,751] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,753] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,755] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,756] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,756] WARN The configuration 'file' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,758] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,759] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,761] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,762] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,762] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,763] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:01:37,764] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:01:37,765] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:01:37,765] INFO Kafka startTimeMs: 1668596497764 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:01:37,811] INFO Kafka cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.connect.util.ConnectUtils:67)
[2022-11-16 12:01:37,814] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:01:37,826] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:01:37,831] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:01:37,832] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:01:37,840] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:01:37,841] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:01:37,842] INFO Kafka startTimeMs: 1668596497840 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:01:38,084] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:01:38,087] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:01:38,102] INFO Kafka Connect standalone worker initialization took 7725ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-11-16 12:01:38,103] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-11-16 12:01:38,105] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:98)
[2022-11-16 12:01:38,105] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2022-11-16 12:01:38,107] INFO Starting FileOffsetBackingStore with file mpconnect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-11-16 12:01:38,124] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2022-11-16 12:01:38,124] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:101)
[2022-11-16 12:01:38,126] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:208)
[2022-11-16 12:01:38,184] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:225)
[2022-11-16 12:01:38,295] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-11-16 12:01:38,296] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-11-16 12:01:38,299] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2022-11-16 12:01:39,047] INFO Started o.e.j.s.ServletContextHandler@3f1ed068{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-11-16 12:01:39,047] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:303)
[2022-11-16 12:01:39,048] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-11-16 12:01:39,414] INFO Successfully tested connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useSSL=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'dbz' (io.debezium.connector.mysql.MySqlConnector:100)
[2022-11-16 12:01:39,426] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:01:39,432] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2022-11-16 12:01:39,448] INFO [CMS-c2|worker] Creating connector CMS-c2 of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:264)
[2022-11-16 12:01:39,450] INFO [CMS-c2|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:01:39,452] INFO [CMS-c2|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:01:39,462] INFO [CMS-c2|worker] Instantiated connector CMS-c2 with version 1.8.0.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:274)
[2022-11-16 12:01:39,463] INFO [CMS-c2|worker] Finished creating connector CMS-c2 (org.apache.kafka.connect.runtime.Worker:299)
[2022-11-16 12:01:39,472] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:01:39,473] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:01:39,478] INFO [CMS-c2|task-0] Creating task CMS-c2-0 (org.apache.kafka.connect.runtime.Worker:498)
[2022-11-16 12:01:39,484] INFO [CMS-c2|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2022-11-16 12:01:39,485] INFO [CMS-c2|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:01:39,490] INFO [CMS-c2|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2022-11-16 12:01:39,493] INFO [CMS-c2|task-0] Instantiated task CMS-c2-0 with version 1.8.0.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:513)
[2022-11-16 12:01:39,495] INFO [CMS-c2|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:01:39,498] INFO [CMS-c2|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task CMS-c2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:526)
[2022-11-16 12:01:39,499] INFO [CMS-c2|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:01:39,499] INFO [CMS-c2|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task CMS-c2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:532)
[2022-11-16 12:01:39,500] INFO [CMS-c2|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task CMS-c2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-11-16 12:01:39,507] INFO [CMS-c2|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:01:39,509] INFO [CMS-c2|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:01:39,512] INFO [CMS-c2|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:593)
[2022-11-16 12:01:39,523] INFO [CMS-c2|task-0] ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-CMS-c2-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:01:39,574] WARN [CMS-c2|task-0] The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:384)
[2022-11-16 12:01:39,580] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:01:39,581] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:01:39,605] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668596499579 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:01:39,615] INFO [CMS-c2|task-0] [Producer clientId=connector-producer-CMS-c2-0] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:01:39,636] INFO Created connector CMS-c2 (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-11-16 12:01:39,644] INFO [CMS-c2|task-0] Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:124)
[2022-11-16 12:01:39,648] INFO [CMS-c2|task-0]    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,649] INFO [CMS-c2|task-0]    database.user = dbz (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,649] INFO [CMS-c2|task-0]    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,650] INFO [CMS-c2|task-0]    database.server.id = 111113 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,653] INFO [CMS-c2|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,654] INFO [CMS-c2|task-0]    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,656] INFO [CMS-c2|task-0]    database.history.kafka.bootstrap.servers = localhost:9094 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,656] INFO [CMS-c2|task-0]    database.history.kafka.topic = schema-changes.inventory (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,658] INFO [CMS-c2|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,660] INFO [CMS-c2|task-0]    name = CMS-c2 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,661] INFO [CMS-c2|task-0]    database.server.name = testdb (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,662] INFO [CMS-c2|task-0]    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:39,786] INFO [CMS-c2|task-0] Found previous partition offset io.debezium.connector.mysql.MySqlPartition@cbb77490: MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000024, currentBinlogPosition=2290, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000024, restartBinlogPosition=2290, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.common.BaseSourceTask:313)
[2022-11-16 12:01:39,847] INFO [CMS-c2|task-0] KafkaDatabaseHistory Consumer config: {enable.auto.commit=false, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, group.id=testdb-dbhistory, auto.offset.reset=earliest, session.timeout.ms=10000, bootstrap.servers=localhost:9094, client.id=testdb-dbhistory, key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, fetch.min.bytes=1} (io.debezium.relational.history.KafkaDatabaseHistory:219)
[2022-11-16 12:01:39,848] INFO [CMS-c2|task-0] KafkaDatabaseHistory Producer config: {bootstrap.servers=localhost:9094, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=1048576, retries=1, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=testdb-dbhistory, linger.ms=0, batch.size=32768, max.block.ms=10000, acks=1} (io.debezium.relational.history.KafkaDatabaseHistory:220)
[2022-11-16 12:01:39,851] INFO [CMS-c2|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = db-history-config-check (io.debezium.util.Threads:270)
[2022-11-16 12:01:39,853] INFO [CMS-c2|task-0] Idempotence will be disabled because acks is set to 1, not set to 'all'. (org.apache.kafka.clients.producer.ProducerConfig:501)
[2022-11-16 12:01:39,854] INFO [CMS-c2|task-0] ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9094]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:01:39,863] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:01:39,864] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:01:39,865] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668596499863 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:01:39,878] INFO [CMS-c2|task-0] [Producer clientId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:01:39,913] INFO [CMS-c2|task-0] Closing connection before starting schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:96)
[2022-11-16 12:01:39,916] INFO [CMS-c2|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:01:39,930] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:01:40,018] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:01:40,019] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:01:40,025] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668596500018 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:01:40,055] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:01:40,063] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:01:40,063] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:01:40,065] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:01:40,065] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:01:40,066] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:01:40,069] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:01:40,069] WARN [CMS-c2|task-0] Database history was not found but was expected (io.debezium.connector.mysql.MySqlConnectorTask:351)
[2022-11-16 12:01:40,071] ERROR [CMS-c2|task-0] WorkerSourceTask{id=CMS-c2-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:195)
io.debezium.DebeziumException: The db history topic is missing. You may attempt to recover it by reconfiguring the connector to SCHEMA_ONLY_RECOVERY
	at io.debezium.connector.mysql.MySqlConnectorTask.validateAndLoadDatabaseHistory(MySqlConnectorTask.java:363)
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:108)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:130)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.initializeAndStart(WorkerSourceTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:186)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[2022-11-16 12:01:40,075] INFO [CMS-c2|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:238)
[2022-11-16 12:01:40,083] INFO [CMS-c2|task-0] [Producer clientId=testdb-dbhistory] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1249)
[2022-11-16 12:01:40,087] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:01:40,088] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:01:40,089] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:01:40,093] INFO [CMS-c2|task-0] App info kafka.producer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:01:40,095] INFO [CMS-c2|task-0] [Producer clientId=connector-producer-CMS-c2-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1249)
[2022-11-16 12:01:40,101] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:01:40,102] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:01:40,103] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:01:40,104] INFO [CMS-c2|task-0] App info kafka.producer for connector-producer-CMS-c2-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:01:46,517] INFO Successfully tested connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useSSL=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'dbz' (io.debezium.connector.mysql.MySqlConnector:100)
[2022-11-16 12:01:46,520] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:01:46,521] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2022-11-16 12:01:46,524] INFO [CMS-connector5|worker] Creating connector CMS-connector5 of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:264)
[2022-11-16 12:01:46,526] INFO [CMS-connector5|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connector5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:01:46,527] INFO [CMS-connector5|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connector5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:01:46,529] INFO [CMS-connector5|worker] Instantiated connector CMS-connector5 with version 1.8.0.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:274)
[2022-11-16 12:01:46,532] INFO [CMS-connector5|worker] Finished creating connector CMS-connector5 (org.apache.kafka.connect.runtime.Worker:299)
[2022-11-16 12:01:46,533] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connector5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:01:46,534] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connector5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:01:46,535] INFO [CMS-connector5|task-0] Creating task CMS-connector5-0 (org.apache.kafka.connect.runtime.Worker:498)
[2022-11-16 12:01:46,537] INFO [CMS-connector5|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connector5
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2022-11-16 12:01:46,538] INFO [CMS-connector5|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connector5
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:01:46,540] INFO [CMS-connector5|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2022-11-16 12:01:46,542] INFO [CMS-connector5|task-0] Instantiated task CMS-connector5-0 with version 1.8.0.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:513)
[2022-11-16 12:01:46,546] INFO [CMS-connector5|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:01:46,546] INFO [CMS-connector5|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task CMS-connector5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:526)
[2022-11-16 12:01:46,548] INFO [CMS-connector5|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:01:46,549] INFO [CMS-connector5|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task CMS-connector5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:532)
[2022-11-16 12:01:46,549] INFO [CMS-connector5|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task CMS-connector5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-11-16 12:01:46,551] INFO [CMS-connector5|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connector5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:01:46,551] INFO [CMS-connector5|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connector5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:01:46,552] INFO [CMS-connector5|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:593)
[2022-11-16 12:01:46,553] INFO [CMS-connector5|task-0] ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-CMS-connector5-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:01:46,566] WARN [CMS-connector5|task-0] The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:384)
[2022-11-16 12:01:46,569] INFO [CMS-connector5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:01:46,576] INFO [CMS-connector5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:01:46,578] INFO [CMS-connector5|task-0] Kafka startTimeMs: 1668596506569 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:01:46,596] INFO [CMS-connector5|task-0] Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:124)
[2022-11-16 12:01:46,601] INFO [CMS-connector5|task-0]    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,604] INFO [CMS-connector5|task-0]    database.user = dbz (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,609] INFO [CMS-connector5|task-0] [Producer clientId=connector-producer-CMS-connector5-0] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:01:46,609] INFO [CMS-connector5|task-0]    config.storage.topic = my_connect_config (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,612] INFO [CMS-connector5|task-0]    database.server.id = 1444 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,614] INFO [CMS-connector5|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,614] INFO [CMS-connector5|task-0]    database.history.kafka.bootstrap.servers = localhost:9094 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,615] INFO [CMS-connector5|task-0]    database.history.kafka.topic = schema-changes.inventory (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,616] INFO [CMS-connector5|task-0]    status.storage.topic = my_connect_statuses (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,618] INFO [CMS-connector5|task-0]    database.server.name = testdb (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,619] INFO [CMS-connector5|task-0]    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,620] INFO [CMS-connector5|task-0]    heartbeat.interval?.ms = 5000 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,627] INFO [CMS-connector5|task-0]    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,630] INFO [CMS-connector5|task-0]    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,631] INFO [CMS-connector5|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,631] INFO [CMS-connector5|task-0]    name = CMS-connector5 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,632] INFO [CMS-connector5|task-0]    offset.storage.topic = my_connect_offsets (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:01:46,661] INFO [CMS-connector5|task-0] Found previous partition offset io.debezium.connector.mysql.MySqlPartition@cbb77490: MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000022, currentBinlogPosition=646, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000022, restartBinlogPosition=646, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.common.BaseSourceTask:313)
[2022-11-16 12:01:46,683] INFO [CMS-connector5|task-0] KafkaDatabaseHistory Consumer config: {enable.auto.commit=false, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, group.id=testdb-dbhistory, auto.offset.reset=earliest, session.timeout.ms=10000, bootstrap.servers=localhost:9094, client.id=testdb-dbhistory, key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, fetch.min.bytes=1} (io.debezium.relational.history.KafkaDatabaseHistory:219)
[2022-11-16 12:01:46,694] INFO [CMS-connector5|task-0] KafkaDatabaseHistory Producer config: {bootstrap.servers=localhost:9094, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=1048576, retries=1, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=testdb-dbhistory, linger.ms=0, batch.size=32768, max.block.ms=10000, acks=1} (io.debezium.relational.history.KafkaDatabaseHistory:220)
[2022-11-16 12:01:46,694] INFO [CMS-connector5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = db-history-config-check (io.debezium.util.Threads:270)
[2022-11-16 12:01:46,698] INFO [CMS-connector5|task-0] Idempotence will be disabled because acks is set to 1, not set to 'all'. (org.apache.kafka.clients.producer.ProducerConfig:501)
[2022-11-16 12:01:46,699] INFO [CMS-connector5|task-0] ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9094]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:01:46,711] INFO [CMS-connector5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:01:46,712] INFO [CMS-connector5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:01:46,712] INFO [CMS-connector5|task-0] Kafka startTimeMs: 1668596506711 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:01:46,714] INFO [CMS-connector5|task-0] Closing connection before starting schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:96)
[2022-11-16 12:01:46,721] INFO [CMS-connector5|task-0] [Producer clientId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:01:46,722] INFO [CMS-connector5|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:01:46,726] INFO [CMS-connector5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:01:46,738] INFO [CMS-connector5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:01:46,744] INFO [CMS-connector5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:01:46,746] INFO [CMS-connector5|task-0] Kafka startTimeMs: 1668596506738 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:01:46,761] INFO [CMS-connector5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:01:46,764] INFO [CMS-connector5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:01:46,765] INFO [CMS-connector5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:01:46,767] INFO [CMS-connector5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:01:46,768] INFO [CMS-connector5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:01:46,769] INFO [CMS-connector5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:01:46,774] INFO [CMS-connector5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:01:46,775] WARN [CMS-connector5|task-0] Database history was not found but was expected (io.debezium.connector.mysql.MySqlConnectorTask:351)
[2022-11-16 12:01:46,779] ERROR [CMS-connector5|task-0] WorkerSourceTask{id=CMS-connector5-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:195)
io.debezium.DebeziumException: The db history topic is missing. You may attempt to recover it by reconfiguring the connector to SCHEMA_ONLY_RECOVERY
	at io.debezium.connector.mysql.MySqlConnectorTask.validateAndLoadDatabaseHistory(MySqlConnectorTask.java:363)
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:108)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:130)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.initializeAndStart(WorkerSourceTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:186)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[2022-11-16 12:01:46,786] INFO [CMS-connector5|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:238)
[2022-11-16 12:01:46,788] INFO [CMS-connector5|task-0] [Producer clientId=testdb-dbhistory] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1249)
[2022-11-16 12:01:46,799] INFO [CMS-connector5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:01:46,801] INFO [CMS-connector5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:01:46,802] INFO [CMS-connector5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:01:46,803] INFO [CMS-connector5|task-0] App info kafka.producer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:01:46,805] INFO [CMS-connector5|task-0] [Producer clientId=connector-producer-CMS-connector5-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1249)
[2022-11-16 12:01:46,815] INFO [CMS-connector5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:01:46,819] INFO [CMS-connector5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:01:46,820] INFO [CMS-connector5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:01:46,821] INFO [CMS-connector5|task-0] App info kafka.producer for connector-producer-CMS-connector5-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:02:18,195] INFO Successfully tested connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useSSL=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'dbz' (io.debezium.connector.mysql.MySqlConnector:100)
[2022-11-16 12:02:18,206] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:02:18,209] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2022-11-16 12:02:18,225] INFO [CMS-connecto r5|worker] Creating connector CMS-connecto r5 of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:264)
[2022-11-16 12:02:18,226] INFO [CMS-connecto r5|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:02:18,227] INFO [CMS-connecto r5|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:02:18,233] INFO [CMS-connecto r5|worker] Instantiated connector CMS-connecto r5 with version 1.8.0.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:274)
[2022-11-16 12:02:18,233] INFO [CMS-connecto r5|worker] Finished creating connector CMS-connecto r5 (org.apache.kafka.connect.runtime.Worker:299)
[2022-11-16 12:02:18,237] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:02:18,242] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:02:18,244] INFO [CMS-connecto r5|task-0] Creating task CMS-connecto r5-0 (org.apache.kafka.connect.runtime.Worker:498)
[2022-11-16 12:02:18,247] INFO [CMS-connecto r5|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2022-11-16 12:02:18,250] INFO [CMS-connecto r5|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:02:18,255] INFO [CMS-connecto r5|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2022-11-16 12:02:18,259] INFO [CMS-connecto r5|task-0] Instantiated task CMS-connecto r5-0 with version 1.8.0.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:513)
[2022-11-16 12:02:18,260] INFO [CMS-connecto r5|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:02:18,261] INFO [CMS-connecto r5|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task CMS-connecto r5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:526)
[2022-11-16 12:02:18,262] INFO [CMS-connecto r5|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:02:18,262] INFO [CMS-connecto r5|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task CMS-connecto r5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:532)
[2022-11-16 12:02:18,263] INFO [CMS-connecto r5|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task CMS-connecto r5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-11-16 12:02:18,265] INFO [CMS-connecto r5|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:02:18,266] INFO [CMS-connecto r5|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:02:18,267] INFO [CMS-connecto r5|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:593)
[2022-11-16 12:02:18,273] INFO [CMS-connecto r5|task-0] ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-CMS-connecto r5-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:02:18,280] WARN [CMS-connecto r5|task-0] The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:384)
[2022-11-16 12:02:18,287] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:02:18,288] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:02:18,289] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668596538287 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:02:18,313] INFO [CMS-connecto r5|task-0] Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:124)
[2022-11-16 12:02:18,315] INFO [CMS-connecto r5|task-0]    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,336] INFO [CMS-connecto r5|task-0]    database.user = dbz (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,341] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:02:18,342] INFO [CMS-connecto r5|task-0]    config.storage.topic = my_connect_config (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,345] INFO [CMS-connecto r5|task-0]    database.server.id = 14404 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,346] INFO [CMS-connecto r5|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,348] INFO [CMS-connecto r5|task-0]    database.history.kafka.bootstrap.servers = localhost:9094 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,348] INFO [CMS-connecto r5|task-0]    database.history.kafka.topic = schema-changes.inventory (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,349] INFO [CMS-connecto r5|task-0]    status.storage.topic = my_connect_statuses (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,350] INFO [CMS-connecto r5|task-0]    database.server.name = testdb (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,353] INFO [CMS-connecto r5|task-0]    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,353] INFO [CMS-connecto r5|task-0]    heartbeat.interval?.ms = 5000 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,354] INFO [CMS-connecto r5|task-0]    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,355] INFO [CMS-connecto r5|task-0]    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,356] INFO [CMS-connecto r5|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,356] INFO [CMS-connecto r5|task-0]    name = CMS-connecto r5 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,358] INFO [CMS-connecto r5|task-0]    offset.storage.topic = my_connect_offsets (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:02:18,381] INFO [CMS-connecto r5|task-0] No previous offsets found (io.debezium.connector.common.BaseSourceTask:318)
[2022-11-16 12:02:18,393] INFO [CMS-connecto r5|task-0] KafkaDatabaseHistory Consumer config: {enable.auto.commit=false, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, group.id=testdb-dbhistory, auto.offset.reset=earliest, session.timeout.ms=10000, bootstrap.servers=localhost:9094, client.id=testdb-dbhistory, key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, fetch.min.bytes=1} (io.debezium.relational.history.KafkaDatabaseHistory:219)
[2022-11-16 12:02:18,405] INFO [CMS-connecto r5|task-0] KafkaDatabaseHistory Producer config: {bootstrap.servers=localhost:9094, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=1048576, retries=1, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=testdb-dbhistory, linger.ms=0, batch.size=32768, max.block.ms=10000, acks=1} (io.debezium.relational.history.KafkaDatabaseHistory:220)
[2022-11-16 12:02:18,406] INFO [CMS-connecto r5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = db-history-config-check (io.debezium.util.Threads:270)
[2022-11-16 12:02:18,409] INFO [CMS-connecto r5|task-0] Idempotence will be disabled because acks is set to 1, not set to 'all'. (org.apache.kafka.clients.producer.ProducerConfig:501)
[2022-11-16 12:02:18,410] INFO [CMS-connecto r5|task-0] ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9094]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:02:18,418] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:02:18,420] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:02:18,425] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668596538418 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:02:18,427] INFO [CMS-connecto r5|task-0] Closing connection before starting schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:96)
[2022-11-16 12:02:18,430] INFO [CMS-connecto r5|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:02:18,432] INFO [CMS-connecto r5|task-0] Connector started for the first time, database history recovery will not be executed (io.debezium.connector.mysql.MySqlConnectorTask:346)
[2022-11-16 12:02:18,437] INFO [CMS-connecto r5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:02:18,446] INFO [CMS-connecto r5|task-0] [Producer clientId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:02:18,454] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:02:18,461] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:02:18,461] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668596538454 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:02:18,481] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:02:18,486] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:02:18,489] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:02:18,490] INFO [CMS-connecto r5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:02:18,492] INFO [CMS-connecto r5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:02:18,492] INFO [CMS-connecto r5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:02:18,495] INFO [CMS-connecto r5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:02:18,497] INFO [CMS-connecto r5|task-0] AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-16 12:02:18,503] WARN [CMS-connecto r5|task-0] The configuration 'value.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:02:18,505] WARN [CMS-connecto r5|task-0] The configuration 'batch.size' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:02:18,510] WARN [CMS-connecto r5|task-0] The configuration 'max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:02:18,510] WARN [CMS-connecto r5|task-0] The configuration 'acks' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:02:18,511] WARN [CMS-connecto r5|task-0] The configuration 'buffer.memory' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:02:18,512] WARN [CMS-connecto r5|task-0] The configuration 'key.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:02:18,513] WARN [CMS-connecto r5|task-0] The configuration 'linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:02:18,514] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:02:18,515] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:02:18,516] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668596538514 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:02:18,737] INFO [CMS-connecto r5|task-0] Database history topic '(name=schema-changes.inventory, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=delete, retention.ms=9223372036854775807, retention.bytes=-1})' created (io.debezium.relational.history.KafkaDatabaseHistory:506)
[2022-11-16 12:02:20,090] INFO [CMS-connecto r5|task-0] App info kafka.admin.client for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:02:20,095] INFO [CMS-connecto r5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:02:20,102] INFO [CMS-connecto r5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:02:20,103] INFO [CMS-connecto r5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:02:20,105] INFO [CMS-connecto r5|task-0] Reconnecting after finishing schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:110)
[2022-11-16 12:02:20,154] INFO [CMS-connecto r5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2022-11-16 12:02:20,156] INFO [CMS-connecto r5|task-0] Creating thread debezium-mysqlconnector-testdb-change-event-source-coordinator (io.debezium.util.Threads:287)
[2022-11-16 12:02:20,156] INFO [CMS-connecto r5|task-0] WorkerSourceTask{id=CMS-connecto r5-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:227)
[2022-11-16 12:02:20,157] INFO [CMS-connecto r5|task-0] WorkerSourceTask{id=CMS-connecto r5-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2022-11-16 12:02:20,163] INFO [CMS-connecto r5|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:102)
[2022-11-16 12:02:20,171] INFO [CMS-connecto r5|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:105)
[2022-11-16 12:02:20,182] INFO [CMS-connecto r5|task-0] No previous offset has been found (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:87)
[2022-11-16 12:02:20,183] INFO [CMS-connecto r5|task-0] According to the connector configuration both schema and data will be snapshotted (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:89)
[2022-11-16 12:02:20,184] INFO [CMS-connecto r5|task-0] Snapshot step 1 - Preparing (io.debezium.relational.RelationalSnapshotChangeEventSource:87)
[2022-11-16 12:02:20,188] INFO [CMS-connecto r5|task-0] Snapshot step 2 - Determining captured tables (io.debezium.relational.RelationalSnapshotChangeEventSource:96)
[2022-11-16 12:02:20,190] INFO [CMS-connecto r5|task-0] Read list of available databases (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:118)
[2022-11-16 12:02:20,789] INFO [CMS-connecto r5|task-0] 	 list of available databases is: [information_schema, mysql, performance_schema, sys, testdb] (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:125)
[2022-11-16 12:02:20,795] INFO [CMS-connecto r5|task-0] Read list of available tables in each database (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:133)
[2022-11-16 12:02:21,112] INFO [CMS-connecto r5|task-0] 	snapshot continuing with database(s): [information_schema, performance_schema, testdb, mysql, sys] (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:154)
[2022-11-16 12:02:21,116] INFO [CMS-connecto r5|task-0] Snapshot step 3 - Locking captured tables [testdb.hibernate_sequence, testdb.line_alloc, testdb.line_alloc_aud, testdb.lines_p, testdb.lines_p_aud, testdb.machine_alloc, testdb.machine_alloc_aud, testdb.machines, testdb.machines_aud, testdb.my_revision, testdb.roles, testdb.roles_aud, testdb.user_roles, testdb.user_roles_aud, testdb.users, testdb.users_aud] (io.debezium.relational.RelationalSnapshotChangeEventSource:103)
[2022-11-16 12:02:21,168] INFO [CMS-connecto r5|task-0] Flush and obtain global read lock to prevent writes to database (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:427)
[2022-11-16 12:02:21,171] INFO [CMS-connecto r5|task-0] Snapshot step 4 - Determining snapshot offset (io.debezium.relational.RelationalSnapshotChangeEventSource:109)
[2022-11-16 12:02:21,172] INFO [CMS-connecto r5|task-0] Read binlog position of MySQL primary server (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:275)
[2022-11-16 12:02:21,175] INFO [CMS-connecto r5|task-0] 	 using binlog 'mysql-bin.000029' at position '156' and gtid '' (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:286)
[2022-11-16 12:02:21,175] INFO [CMS-connecto r5|task-0] Snapshot step 5 - Reading structure of captured tables (io.debezium.relational.RelationalSnapshotChangeEventSource:112)
[2022-11-16 12:02:21,176] INFO [CMS-connecto r5|task-0] All eligible tables schema should be captured, capturing: [testdb.hibernate_sequence, testdb.line_alloc, testdb.line_alloc_aud, testdb.lines_p, testdb.lines_p_aud, testdb.machine_alloc, testdb.machine_alloc_aud, testdb.machines, testdb.machines_aud, testdb.my_revision, testdb.roles, testdb.roles_aud, testdb.user_roles, testdb.user_roles_aud, testdb.users, testdb.users_aud] (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:328)
[2022-11-16 12:02:22,665] INFO [CMS-connecto r5|task-0] Reading structure of database 'testdb' (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:350)
[2022-11-16 12:02:23,212] INFO [CMS-connecto r5|task-0] Snapshot step 6 - Persisting schema history (io.debezium.relational.RelationalSnapshotChangeEventSource:116)
[2022-11-16 12:02:23,259] INFO [CMS-connecto r5|task-0] [Producer clientId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to ZYdk-d2NR5mwfg81KAWrBQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:23,795] INFO [CMS-connecto r5|task-0] 19 records sent during previous 00:00:05.535, last recorded offset: {ts_sec=1668596542, file=mysql-bin.000029, pos=156, snapshot=true} (io.debezium.connector.common.BaseSourceTask:182)
[2022-11-16 12:02:24,357] INFO [CMS-connecto r5|task-0] Releasing global read lock to enable MySQL writes (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:433)
[2022-11-16 12:02:24,358] INFO [CMS-connecto r5|task-0] Writes to MySQL tables prevented for a total of 00:00:03.188 (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:437)
[2022-11-16 12:02:24,359] INFO [CMS-connecto r5|task-0] Snapshot step 7 - Snapshotting data (io.debezium.relational.RelationalSnapshotChangeEventSource:128)
[2022-11-16 12:02:24,362] INFO [CMS-connecto r5|task-0] Snapshotting contents of 16 tables while still in transaction (io.debezium.relational.RelationalSnapshotChangeEventSource:298)
[2022-11-16 12:02:24,362] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.hibernate_sequence' (1 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:24,365] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.hibernate_sequence' using select statement: 'SELECT `next_val` FROM `testdb`.`hibernate_sequence`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:24,826] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 3 : {testdb=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:25,186] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 4 : {testdb=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:25,244] INFO [CMS-connecto r5|task-0] 	 Finished exporting 1 records for table 'testdb.hibernate_sequence'; total duration '00:00:00.882' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:25,245] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.line_alloc' (2 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:25,247] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.line_alloc' using select statement: 'SELECT `id`, `allocated_at`, `line_id`, `user_id` FROM `testdb`.`line_alloc`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:25,500] INFO [CMS-connecto r5|task-0] 	 Finished exporting 0 records for table 'testdb.line_alloc'; total duration '00:00:00.255' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:25,501] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.line_alloc_aud' (3 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:25,502] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.line_alloc_aud' using select statement: 'SELECT `id`, `rev`, `revtype`, `allocated_at`, `line_id`, `user_id` FROM `testdb`.`line_alloc_aud`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:25,506] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 5 : {testdb=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:25,686] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 6 : {testdb=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:25,720] INFO [CMS-connecto r5|task-0] 	 Finished exporting 1 records for table 'testdb.line_alloc_aud'; total duration '00:00:00.219' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:25,721] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.lines_p' (4 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:25,721] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.lines_p' using select statement: 'SELECT `id`, `description`, `name`, `revisiondate`, `revisionauthor_id`, `revisionauthor` FROM `testdb`.`lines_p`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:25,793] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 7 : {testdb=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:25,909] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 8 : {testdb=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:26,032] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 9 : {testdb=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:26,078] INFO [CMS-connecto r5|task-0] 	 Finished exporting 3 records for table 'testdb.lines_p'; total duration '00:00:00.357' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:26,080] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.lines_p_aud' (5 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:26,084] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.lines_p_aud' using select statement: 'SELECT `id`, `rev`, `revtype`, `description`, `name`, `revisiondate`, `revisionauthor_id`, `revisionauthor` FROM `testdb`.`lines_p_aud`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:26,152] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 10 : {testdb=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:26,262] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 11 : {testdb=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:26,317] INFO [CMS-connecto r5|task-0] 	 Finished exporting 26 records for table 'testdb.lines_p_aud'; total duration '00:00:00.237' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:26,320] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.machine_alloc' (6 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:26,321] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.machine_alloc' using select statement: 'SELECT `id`, `allocated_at`, `machine_id`, `user_id` FROM `testdb`.`machine_alloc`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:26,335] INFO [CMS-connecto r5|task-0] 	 Finished exporting 0 records for table 'testdb.machine_alloc'; total duration '00:00:00.015' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:26,336] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.machine_alloc_aud' (7 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:26,337] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.machine_alloc_aud' using select statement: 'SELECT `id`, `rev`, `revtype`, `allocated_at`, `machine_id`, `user_id` FROM `testdb`.`machine_alloc_aud`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:26,366] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:26,372] INFO [CMS-connecto r5|task-0] 	 Finished exporting 0 records for table 'testdb.machine_alloc_aud'; total duration '00:00:00.036' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:26,373] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.machines' (8 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:26,374] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.machines' using select statement: 'SELECT `id`, `fese`, `allocated`, `description`, `status`, `typemach`, `line_id`, `revisiondate`, `revisionauthor_id`, `revisionauthor`, `name` FROM `testdb`.`machines`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:26,411] INFO [CMS-connecto r5|task-0] 	 Finished exporting 4 records for table 'testdb.machines'; total duration '00:00:00.038' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:26,412] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.machines_aud' (9 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:26,413] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.machines_aud' using select statement: 'SELECT `id`, `rev`, `revtype`, `fese`, `allocated`, `description`, `status`, `typemach`, `line_id`, `revisiondate`, `revisionauthor_id`, `revisionauthor`, `name` FROM `testdb`.`machines_aud`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:26,486] INFO [CMS-connecto r5|task-0] 	 Finished exporting 7 records for table 'testdb.machines_aud'; total duration '00:00:00.074' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:26,487] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.my_revision' (10 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:26,490] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.my_revision' using select statement: 'SELECT `id`, `timestamp`, `user`, `isline`, `ismachine`, `isuser` FROM `testdb`.`my_revision`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:26,720] INFO [CMS-connecto r5|task-0] 	 Finished exporting 51 records for table 'testdb.my_revision'; total duration '00:00:00.234' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:26,722] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.roles' (11 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:26,727] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.roles' using select statement: 'SELECT `id`, `name` FROM `testdb`.`roles`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:26,953] INFO [CMS-connecto r5|task-0] 	 Finished exporting 3 records for table 'testdb.roles'; total duration '00:00:00.231' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:26,954] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.roles_aud' (12 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:26,955] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.roles_aud' using select statement: 'SELECT `id`, `rev`, `revtype`, `name` FROM `testdb`.`roles_aud`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:27,626] INFO [CMS-connecto r5|task-0] 	 Finished exporting 0 records for table 'testdb.roles_aud'; total duration '00:00:00.672' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:27,627] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.user_roles' (13 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:27,631] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.user_roles' using select statement: 'SELECT `user_id`, `role_id` FROM `testdb`.`user_roles`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:27,802] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 19 : {testdb.testdb.hibernate_sequence=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:27,879] INFO [CMS-connecto r5|task-0] 	 Finished exporting 13 records for table 'testdb.user_roles'; total duration '00:00:00.252' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:27,883] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.user_roles_aud' (14 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:27,885] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.user_roles_aud' using select statement: 'SELECT `rev`, `user_id`, `role_id`, `revtype` FROM `testdb`.`user_roles_aud`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:27,962] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 21 : {testdb.testdb.hibernate_sequence=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:27,963] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:28,131] INFO [CMS-connecto r5|task-0] 	 Finished exporting 21 records for table 'testdb.user_roles_aud'; total duration '00:00:00.248' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:28,134] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 22 : {testdb.testdb.hibernate_sequence=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:28,138] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.users' (15 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:28,142] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.users' using select statement: 'SELECT `id`, `email`, `password`, `username`, `revisionauthor`, `revisiondate` FROM `testdb`.`users`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:28,254] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 23 : {testdb.testdb.hibernate_sequence=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:28,258] INFO [CMS-connecto r5|task-0] 	 Finished exporting 13 records for table 'testdb.users'; total duration '00:00:00.12' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:28,259] INFO [CMS-connecto r5|task-0] Exporting data from table 'testdb.users_aud' (16 of 16 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:334)
[2022-11-16 12:02:28,260] INFO [CMS-connecto r5|task-0] 	 For table 'testdb.users_aud' using select statement: 'SELECT `id`, `rev`, `revtype`, `email`, `password`, `username`, `revisionauthor`, `revisiondate` FROM `testdb`.`users_aud`' (io.debezium.relational.RelationalSnapshotChangeEventSource:342)
[2022-11-16 12:02:28,367] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 24 : {testdb.testdb.hibernate_sequence=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:28,478] INFO [CMS-connecto r5|task-0] 	 Finished exporting 28 records for table 'testdb.users_aud'; total duration '00:00:00.219' (io.debezium.relational.RelationalSnapshotChangeEventSource:387)
[2022-11-16 12:02:28,488] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 25 : {testdb.testdb.hibernate_sequence=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:28,588] INFO [CMS-connecto r5|task-0] Snapshot - Final stage (io.debezium.pipeline.source.AbstractSnapshotChangeEventSource:88)
[2022-11-16 12:02:28,589] INFO [CMS-connecto r5|task-0] Snapshot ended with SnapshotResult [status=COMPLETED, offset=MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000029, currentBinlogPosition=156, currentRowNumber=0, serverId=0, sourceTime=2022-11-16T11:02:28.478Z, threadId=-1, currentQuery=null, tableIds=[testdb.users_aud], databaseName=testdb], snapshotCompleted=true, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000029, restartBinlogPosition=156, restartRowsToSkip=0, restartEventsToSkip=0, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]] (io.debezium.pipeline.ChangeEventSourceCoordinator:154)
[2022-11-16 12:02:28,606] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 26 : {testdb.testdb.hibernate_sequence=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:28,610] INFO [CMS-connecto r5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = binlog-client (io.debezium.util.Threads:270)
[2022-11-16 12:02:28,619] INFO [CMS-connecto r5|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:171)
[2022-11-16 12:02:28,635] INFO [CMS-connecto r5|task-0] Skip 0 events on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:914)
[2022-11-16 12:02:28,635] INFO [CMS-connecto r5|task-0] Skip 0 rows on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:918)
[2022-11-16 12:02:28,637] INFO [CMS-connecto r5|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-16 12:02:28,644] INFO [CMS-connecto r5|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-16 12:02:28,658] INFO [CMS-connecto r5|task-0] Connected to MySQL binlog at localhost:3306, starting at MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000029, currentBinlogPosition=156, currentRowNumber=0, serverId=0, sourceTime=2022-11-16T11:02:28.478Z, threadId=-1, currentQuery=null, tableIds=[testdb.users_aud], databaseName=testdb], snapshotCompleted=true, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000029, restartBinlogPosition=156, restartRowsToSkip=0, restartEventsToSkip=0, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:1203)
[2022-11-16 12:02:28,659] INFO [CMS-connecto r5|task-0] Waiting for keepalive thread to start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:935)
[2022-11-16 12:02:28,660] INFO [CMS-connecto r5|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-16 12:02:28,720] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 27 : {testdb.testdb.hibernate_sequence=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:28,762] INFO [CMS-connecto r5|task-0] Keepalive thread is running (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:942)
[2022-11-16 12:02:28,830] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 28 : {testdb.testdb.hibernate_sequence=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:28,937] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:29,455] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 30 : {testdb.testdb.line_alloc_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:29,702] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 32 : {testdb.testdb.line_alloc_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:29,702] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:29,704] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:29,814] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 33 : {testdb.testdb.line_alloc_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:29,921] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 34 : {testdb.testdb.line_alloc_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:30,031] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 35 : {testdb.testdb.line_alloc_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:30,144] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 36 : {testdb.testdb.line_alloc_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:30,270] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 37 : {testdb.testdb.line_alloc_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:30,391] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 38 : {testdb.testdb.line_alloc_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:30,496] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:30,916] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 41 : {testdb.testdb.lines_p=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:31,045] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 42 : {testdb.testdb.lines_p=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:31,046] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:31,054] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:31,056] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:31,360] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 43 : {testdb.testdb.lines_p=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:31,472] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 44 : {testdb.testdb.lines_p=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:31,583] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 45 : {testdb.testdb.lines_p=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:31,691] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 46 : {testdb.testdb.lines_p=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:31,799] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 47 : {testdb.testdb.lines_p=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:31,910] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 48 : {testdb.testdb.lines_p=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:32,013] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:32,480] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 51 : {testdb.testdb.lines_p_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:32,808] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 53 : {testdb.testdb.lines_p_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:32,809] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:32,814] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:32,818] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:32,820] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:32,919] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 54 : {testdb.testdb.lines_p_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:33,039] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 55 : {testdb.testdb.lines_p_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:33,165] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 56 : {testdb.testdb.lines_p_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:33,283] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 57 : {testdb.testdb.lines_p_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:33,398] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 58 : {testdb.testdb.lines_p_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:33,510] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p_aud-0 to 0 since the associated topicId changed from null to ShrkwYkEQRiE4ExCVdXdqw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:34,039] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 62 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:34,619] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 64 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:34,623] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:34,627] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p_aud-0 to 0 since the associated topicId changed from null to ShrkwYkEQRiE4ExCVdXdqw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:34,630] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:34,633] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:34,634] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:34,750] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 65 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:34,860] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 66 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:34,973] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 67 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:35,080] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 68 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:35,187] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 69 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:35,296] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 70 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:35,405] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 71 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:35,515] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 72 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:35,624] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 73 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:35,734] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 74 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:35,852] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 75 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:35,979] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 76 : {testdb.testdb.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:36,087] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines-0 to 0 since the associated topicId changed from null to DxsJSCBhRKKNIEPhc292fA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:36,839] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 79 : {testdb.testdb.machines_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:37,164] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 81 : {testdb.testdb.machines_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:37,164] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:37,166] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines-0 to 0 since the associated topicId changed from null to DxsJSCBhRKKNIEPhc292fA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:37,168] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p_aud-0 to 0 since the associated topicId changed from null to ShrkwYkEQRiE4ExCVdXdqw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:37,169] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:37,170] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:37,171] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:37,361] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 82 : {testdb.testdb.machines_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:37,481] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 83 : {testdb.testdb.machines_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:37,587] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 84 : {testdb.testdb.machines_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:37,702] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 85 : {testdb.testdb.machines_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:37,827] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 86 : {testdb.testdb.machines_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:37,955] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 87 : {testdb.testdb.machines_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:38,073] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 88 : {testdb.testdb.machines_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:38,178] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines_aud-0 to 0 since the associated topicId changed from null to A0ZBUnNZTB6ZFp9Cm6Un4w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:38,916] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 91 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:39,235] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 93 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:39,236] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:39,241] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines-0 to 0 since the associated topicId changed from null to DxsJSCBhRKKNIEPhc292fA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:39,244] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p_aud-0 to 0 since the associated topicId changed from null to ShrkwYkEQRiE4ExCVdXdqw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:39,246] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines_aud-0 to 0 since the associated topicId changed from null to A0ZBUnNZTB6ZFp9Cm6Un4w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:39,247] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:39,248] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:39,249] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:39,586] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 94 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:39,711] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 95 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:39,819] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 96 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:39,930] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 97 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:40,058] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 98 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:40,183] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 99 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:40,300] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 100 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:40,415] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 101 : {testdb.testdb.my_revision=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:40,517] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.my_revision-0 to 0 since the associated topicId changed from null to 3pLlUZquRSurfFU2HpQjBw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:41,045] INFO [CMS-connecto r5|task-0] 80 records sent during previous 00:00:17.251, last recorded offset: {ts_sec=1668596548, file=mysql-bin.000029, pos=156} (io.debezium.connector.common.BaseSourceTask:182)
[2022-11-16 12:02:41,649] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 108 : {testdb.testdb.roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:41,936] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 110 : {testdb.testdb.roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:41,936] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:41,940] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines-0 to 0 since the associated topicId changed from null to DxsJSCBhRKKNIEPhc292fA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:41,942] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p_aud-0 to 0 since the associated topicId changed from null to ShrkwYkEQRiE4ExCVdXdqw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:41,943] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines_aud-0 to 0 since the associated topicId changed from null to A0ZBUnNZTB6ZFp9Cm6Un4w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:41,944] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:41,945] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:41,946] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:41,947] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.my_revision-0 to 0 since the associated topicId changed from null to 3pLlUZquRSurfFU2HpQjBw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:42,053] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 111 : {testdb.testdb.roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:42,161] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 112 : {testdb.testdb.roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:42,270] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 113 : {testdb.testdb.roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:42,386] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 114 : {testdb.testdb.roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:42,505] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 115 : {testdb.testdb.roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:42,610] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.roles-0 to 0 since the associated topicId changed from null to JlQvSlznRIyMOpNzEll_kg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,136] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 118 : {testdb.testdb.user_roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:43,272] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 120 : {testdb.testdb.user_roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:43,273] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,277] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.roles-0 to 0 since the associated topicId changed from null to JlQvSlznRIyMOpNzEll_kg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,279] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines-0 to 0 since the associated topicId changed from null to DxsJSCBhRKKNIEPhc292fA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,281] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p_aud-0 to 0 since the associated topicId changed from null to ShrkwYkEQRiE4ExCVdXdqw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,283] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines_aud-0 to 0 since the associated topicId changed from null to A0ZBUnNZTB6ZFp9Cm6Un4w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,285] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,286] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,288] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,291] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.my_revision-0 to 0 since the associated topicId changed from null to 3pLlUZquRSurfFU2HpQjBw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:43,440] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 121 : {testdb.testdb.user_roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:43,548] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 122 : {testdb.testdb.user_roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:43,656] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 123 : {testdb.testdb.user_roles=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:43,766] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.user_roles-0 to 0 since the associated topicId changed from null to vmx9BYiUS6q9aSfNE-hGRA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,036] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 126 : {testdb.testdb.user_roles_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:44,160] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 128 : {testdb.testdb.user_roles_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:44,162] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,164] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.roles-0 to 0 since the associated topicId changed from null to JlQvSlznRIyMOpNzEll_kg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,165] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines-0 to 0 since the associated topicId changed from null to DxsJSCBhRKKNIEPhc292fA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,166] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p_aud-0 to 0 since the associated topicId changed from null to ShrkwYkEQRiE4ExCVdXdqw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,167] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines_aud-0 to 0 since the associated topicId changed from null to A0ZBUnNZTB6ZFp9Cm6Un4w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,168] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,169] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,170] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.user_roles-0 to 0 since the associated topicId changed from null to vmx9BYiUS6q9aSfNE-hGRA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,171] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,171] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.my_revision-0 to 0 since the associated topicId changed from null to 3pLlUZquRSurfFU2HpQjBw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,268] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 129 : {testdb.testdb.user_roles_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:44,376] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 130 : {testdb.testdb.user_roles_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:44,486] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 131 : {testdb.testdb.user_roles_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:44,592] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.user_roles_aud-0 to 0 since the associated topicId changed from null to 9VjR1ti5RB2CQX4zcpCf1A (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:44,882] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 134 : {testdb.testdb.users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:45,103] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 136 : {testdb.testdb.users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:45,104] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,107] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.roles-0 to 0 since the associated topicId changed from null to JlQvSlznRIyMOpNzEll_kg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,109] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines-0 to 0 since the associated topicId changed from null to DxsJSCBhRKKNIEPhc292fA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,110] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p_aud-0 to 0 since the associated topicId changed from null to ShrkwYkEQRiE4ExCVdXdqw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,111] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines_aud-0 to 0 since the associated topicId changed from null to A0ZBUnNZTB6ZFp9Cm6Un4w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,112] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,114] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,115] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.user_roles_aud-0 to 0 since the associated topicId changed from null to 9VjR1ti5RB2CQX4zcpCf1A (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,116] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.user_roles-0 to 0 since the associated topicId changed from null to vmx9BYiUS6q9aSfNE-hGRA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,117] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,118] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.my_revision-0 to 0 since the associated topicId changed from null to 3pLlUZquRSurfFU2HpQjBw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:45,222] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 137 : {testdb.testdb.users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:45,330] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 138 : {testdb.testdb.users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:45,438] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 139 : {testdb.testdb.users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:45,553] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 140 : {testdb.testdb.users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:45,673] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 141 : {testdb.testdb.users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:45,785] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 142 : {testdb.testdb.users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:45,906] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.users-0 to 0 since the associated topicId changed from null to TaCngcjAS72mj-uxJmbnqQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,190] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 145 : {testdb.testdb.users_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:46,360] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 147 : {testdb.testdb.users_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:46,360] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.line_alloc_aud-0 to 0 since the associated topicId changed from null to cvvlYo88SSSvbI5Z3Y248w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,363] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.users-0 to 0 since the associated topicId changed from null to TaCngcjAS72mj-uxJmbnqQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,365] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.roles-0 to 0 since the associated topicId changed from null to JlQvSlznRIyMOpNzEll_kg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,366] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines-0 to 0 since the associated topicId changed from null to DxsJSCBhRKKNIEPhc292fA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,367] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p_aud-0 to 0 since the associated topicId changed from null to ShrkwYkEQRiE4ExCVdXdqw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,368] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.machines_aud-0 to 0 since the associated topicId changed from null to A0ZBUnNZTB6ZFp9Cm6Un4w (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,370] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.hibernate_sequence-0 to 0 since the associated topicId changed from null to iHJcUGjMSjiAm5KO4DXA6Q (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,371] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,372] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.user_roles_aud-0 to 0 since the associated topicId changed from null to 9VjR1ti5RB2CQX4zcpCf1A (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,373] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.user_roles-0 to 0 since the associated topicId changed from null to vmx9BYiUS6q9aSfNE-hGRA (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,374] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb-0 to 0 since the associated topicId changed from null to 92ZuRYiST6CaxIGjdV07SQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,375] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.my_revision-0 to 0 since the associated topicId changed from null to 3pLlUZquRSurfFU2HpQjBw (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:02:46,466] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 148 : {testdb.testdb.users_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:46,586] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 149 : {testdb.testdb.users_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:46,697] WARN [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Error while fetching metadata with correlation id 150 : {testdb.testdb.users_aud=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1103)
[2022-11-16 12:02:46,804] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.users_aud-0 to 0 since the associated topicId changed from null to dEaucYVfRXa3fvcGu7NdOQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:11:38,867] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-11-16 12:11:38,878] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=C:\Users\1s0\Desktop\kafka_2.12-3.2.1/logs, -Dlog4j.configuration=file:C:\Users\1s0\Desktop\kafka_2.12-3.2.1/config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_333, 25.333-b02
	jvm.classpath = C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\activation-1.1.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\argparse4j-0.7.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\audience-annotations-0.5.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\commons-cli-1.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\commons-lang3-3.8.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-api-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-basic-auth-extension-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-file-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-json-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-mirror-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-mirror-client-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-runtime-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-transforms-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\hk2-api-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\hk2-locator-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\hk2-utils-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-annotations-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-core-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-databind-2.12.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-dataformat-csv-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-datatype-jdk8-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-jaxrs-base-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-jaxrs-json-provider-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-module-jaxb-annotations-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-module-scala_2.12-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.activation-api-1.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.inject-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.validation-api-2.0.2.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\javassist-3.27.0-GA.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\javax.servlet-api-3.1.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jaxb-api-2.3.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-client-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-common-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-container-servlet-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-container-servlet-core-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-hk2-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-server-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-client-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-continuation-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-http-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-io-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-security-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-server-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-servlet-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-servlets-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-util-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-util-ajax-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jline-3.21.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jopt-simple-5.0.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jose4j-0.7.9.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-clients-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-log4j-appender-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-metadata-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-raft-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-server-common-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-shell-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-storage-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-storage-api-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-examples-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-scala_2.12-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-test-utils-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-tools-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka_2.12-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\lz4-java-1.8.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\maven-artifact-3.8.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\metrics-core-2.2.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\metrics-core-4.1.12.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\MySqlConnector.class;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-buffer-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-codec-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-common-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-handler-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-resolver-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-tcnative-classes-2.0.46.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-classes-epoll-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-native-epoll-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-native-unix-common-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\osgi-resource-locator-1.0.3.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\paranamer-2.8.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\plexus-utils-3.3.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\reflections-0.9.12.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\reload4j-1.2.19.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\rocksdbjni-6.29.4.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-collection-compat_2.12-2.6.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-java8-compat_2.12-1.0.2.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-library-2.12.15.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-logging_2.12-3.9.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-reflect-2.12.15.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\slf4j-api-1.7.36.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\slf4j-reload4j-1.7.36.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\snappy-java-1.1.8.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\trogdor-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\zookeeper-3.6.3.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\zookeeper-jute-3.6.3.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\zstd-jni-1.5.2-1.jar
	os.spec = Windows 10, amd64, 10.0
	os.vcpus = 4
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-11-16 12:11:38,887] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-11-16 12:11:39,023] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\bin (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:39,161] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/bin/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:39,162] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:39,164] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:39,165] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:39,168] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\config (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:39,178] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/config/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:39,180] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\debezium (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:41,038] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/debezium/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:41,039] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:41,041] INFO Added plugin 'io.debezium.converters.ByteBufferConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:41,042] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:41,044] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:41,045] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:41,046] INFO Added plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:41,047] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:41,048] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:41,371] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:41,415] WARN Plugin path contains both java archives and class files. Returning only the archives (org.apache.kafka.connect.runtime.isolation.PluginUtils:294)
[2022-11-16 12:11:45,967] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/libs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:45,968] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,970] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,971] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,972] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,973] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,973] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,975] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,976] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,976] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,977] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,978] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,978] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,979] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,979] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,980] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,981] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,981] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,982] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,983] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,984] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,984] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,985] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,986] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,986] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,987] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,987] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,988] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,989] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,989] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,993] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,994] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,994] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,995] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,996] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,997] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,997] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,998] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,999] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:45,999] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,000] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,001] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,001] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,002] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,003] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,004] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,004] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,005] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,006] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,009] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,010] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,011] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,011] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-16 12:11:46,013] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\licenses (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:46,016] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/licenses/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:46,017] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\logs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:46,354] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/logs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:46,356] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\serverdata (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:46,369] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/serverdata/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:46,377] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\site-docs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:46,388] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/site-docs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:46,390] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\tmp (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:46,394] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/tmp/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:46,396] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\zookeeper-data (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-16 12:11:46,400] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/zookeeper-data/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:48,173] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-16 12:11:48,176] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,177] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,177] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,178] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,179] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,179] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,181] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,182] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,184] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,185] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,186] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,187] INFO Added aliases 'ByteBufferConverter' and 'ByteBuffer' to plugin 'io.debezium.converters.ByteBufferConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,188] INFO Added aliases 'CloudEventsConverter' and 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,191] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,193] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,194] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,194] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,195] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,196] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,197] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,197] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,198] INFO Added aliases 'ByteBufferConverter' and 'ByteBuffer' to plugin 'io.debezium.converters.ByteBufferConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,198] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,199] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,200] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,200] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,201] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,202] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,202] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,204] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,207] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,208] INFO Added alias 'ReadToInsertEvent' to plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,209] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,210] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,210] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,211] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,212] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,213] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,214] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,214] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,215] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,216] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,217] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,218] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,219] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,223] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,223] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-16 12:11:48,224] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,225] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,226] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-16 12:11:48,267] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = All
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = mpconnect.offsets
	plugin.path = []
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:376)
[2022-11-16 12:11:48,268] WARN The worker has been configured with one or more internal converter properties ([internal.key.converter, schemas.enable, internal.value.converter, schemas.enable]). Support for these properties was deprecated in version 2.0 and removed in version 3.0, and specifying them will have no effect. Instead, an instance of the JsonConverter with schemas.enable set to false will be used. For more information, please visit http://kafka.apache.org/documentation/#upgrade and consult the upgrade notesfor the 3.0 release. (org.apache.kafka.connect.runtime.WorkerConfig:316)
[2022-11-16 12:11:48,273] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:51)
[2022-11-16 12:11:48,278] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-16 12:11:48,430] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,431] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,433] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,435] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,436] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,437] WARN The configuration 'file' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,437] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,438] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,439] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,440] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,445] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,449] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:11:48,451] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:11:48,452] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:11:48,453] INFO Kafka startTimeMs: 1668597108450 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:11:49,807] INFO Kafka cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.connect.util.ConnectUtils:67)
[2022-11-16 12:11:49,815] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:11:50,070] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:11:50,082] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:11:50,085] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:11:50,115] INFO Logging initialized @12273ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-11-16 12:11:58,700] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:117)
[2022-11-16 12:11:58,711] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:188)
[2022-11-16 12:11:59,760] INFO jetty-9.4.44.v20210927; built: 2021-09-27T23:02:44.612Z; git: 8da83308eeca865e495e53ef315a249d63ba9332; jvm 1.8.0_333-b02 (org.eclipse.jetty.server.Server:375)
[2022-11-16 12:12:00,125] INFO Started http_8083@4defd42{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-11-16 12:12:00,129] INFO Started @22287ms (org.eclipse.jetty.server.Server:415)
[2022-11-16 12:12:00,331] INFO Advertised URI: http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:355)
[2022-11-16 12:12:00,333] INFO REST server listening at http://192.168.31.41:8083/, advertising URL http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2022-11-16 12:12:00,335] INFO Advertised URI: http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:355)
[2022-11-16 12:12:00,335] INFO REST admin endpoints at http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-11-16 12:12:00,338] INFO Advertised URI: http://192.168.31.41:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:355)
[2022-11-16 12:12:00,339] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2022-11-16 12:12:00,357] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:51)
[2022-11-16 12:12:00,359] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-16 12:12:00,376] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,376] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,377] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,378] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,378] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,379] WARN The configuration 'file' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,380] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,381] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,382] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,385] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,385] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,386] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:00,387] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:00,387] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:00,388] INFO Kafka startTimeMs: 1668597120387 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:00,418] INFO Kafka cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.connect.util.ConnectUtils:67)
[2022-11-16 12:12:00,421] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:00,432] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:00,434] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:00,435] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:00,445] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:00,445] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:00,446] INFO Kafka startTimeMs: 1668597120445 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:00,669] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:12:00,672] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:12:00,683] INFO Kafka Connect standalone worker initialization took 21813ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-11-16 12:12:00,684] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-11-16 12:12:00,686] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:98)
[2022-11-16 12:12:00,687] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2022-11-16 12:12:00,691] INFO Starting FileOffsetBackingStore with file mpconnect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-11-16 12:12:01,628] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2022-11-16 12:12:01,629] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:101)
[2022-11-16 12:12:01,631] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:208)
[2022-11-16 12:12:01,719] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:225)
[2022-11-16 12:12:02,295] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-11-16 12:12:02,296] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-11-16 12:12:02,298] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2022-11-16 12:12:04,498] INFO Started o.e.j.s.ServletContextHandler@2e645fbd{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-11-16 12:12:04,498] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:303)
[2022-11-16 12:12:04,499] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-11-16 12:12:05,728] INFO Successfully tested connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useSSL=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'dbz' (io.debezium.connector.mysql.MySqlConnector:100)
[2022-11-16 12:12:05,799] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:12:05,803] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2022-11-16 12:12:05,819] INFO [CMS-c2|worker] Creating connector CMS-c2 of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:264)
[2022-11-16 12:12:05,820] INFO [CMS-c2|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:12:05,822] INFO [CMS-c2|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:12:06,098] INFO [CMS-c2|worker] Instantiated connector CMS-c2 with version 1.8.0.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:274)
[2022-11-16 12:12:06,099] INFO [CMS-c2|worker] Finished creating connector CMS-c2 (org.apache.kafka.connect.runtime.Worker:299)
[2022-11-16 12:12:06,111] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:12:06,113] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:12:06,120] INFO [CMS-c2|task-0] Creating task CMS-c2-0 (org.apache.kafka.connect.runtime.Worker:498)
[2022-11-16 12:12:06,126] INFO [CMS-c2|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2022-11-16 12:12:06,128] INFO [CMS-c2|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:12:06,132] INFO [CMS-c2|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2022-11-16 12:12:06,154] INFO [CMS-c2|task-0] Instantiated task CMS-c2-0 with version 1.8.0.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:513)
[2022-11-16 12:12:06,157] INFO [CMS-c2|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:12:06,157] INFO [CMS-c2|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task CMS-c2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:526)
[2022-11-16 12:12:06,159] INFO [CMS-c2|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:12:06,160] INFO [CMS-c2|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task CMS-c2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:532)
[2022-11-16 12:12:06,161] INFO [CMS-c2|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task CMS-c2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-11-16 12:12:06,168] INFO [CMS-c2|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:12:06,170] INFO [CMS-c2|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:12:06,174] INFO [CMS-c2|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:593)
[2022-11-16 12:12:06,184] INFO [CMS-c2|task-0] ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-CMS-c2-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:12:06,239] WARN [CMS-c2|task-0] The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:384)
[2022-11-16 12:12:06,241] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:06,243] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:06,246] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668597126241 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:06,264] INFO [CMS-c2|task-0] [Producer clientId=connector-producer-CMS-c2-0] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:06,275] INFO Created connector CMS-c2 (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-11-16 12:12:06,282] INFO [CMS-c2|task-0] Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:124)
[2022-11-16 12:12:06,286] INFO [CMS-c2|task-0]    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,287] INFO [CMS-c2|task-0]    database.user = dbz (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,288] INFO [CMS-c2|task-0]    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,289] INFO [CMS-c2|task-0]    database.server.id = 111113 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,291] INFO [CMS-c2|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,292] INFO [CMS-c2|task-0]    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,295] INFO [CMS-c2|task-0]    database.history.kafka.bootstrap.servers = localhost:9094 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,297] INFO [CMS-c2|task-0]    database.history.kafka.topic = schema-changes.inventory (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,298] INFO [CMS-c2|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,300] INFO [CMS-c2|task-0]    name = CMS-c2 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,301] INFO [CMS-c2|task-0]    database.server.name = testdb (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,302] INFO [CMS-c2|task-0]    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:06,833] INFO [CMS-c2|task-0] Found previous partition offset io.debezium.connector.mysql.MySqlPartition@cbb77490: MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000024, currentBinlogPosition=2290, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000024, restartBinlogPosition=2290, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.common.BaseSourceTask:313)
[2022-11-16 12:12:06,913] INFO [CMS-c2|task-0] KafkaDatabaseHistory Consumer config: {enable.auto.commit=false, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, group.id=testdb-dbhistory, auto.offset.reset=earliest, session.timeout.ms=10000, bootstrap.servers=localhost:9094, client.id=testdb-dbhistory, key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, fetch.min.bytes=1} (io.debezium.relational.history.KafkaDatabaseHistory:219)
[2022-11-16 12:12:06,914] INFO [CMS-c2|task-0] KafkaDatabaseHistory Producer config: {bootstrap.servers=localhost:9094, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=1048576, retries=1, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=testdb-dbhistory, linger.ms=0, batch.size=32768, max.block.ms=10000, acks=1} (io.debezium.relational.history.KafkaDatabaseHistory:220)
[2022-11-16 12:12:06,917] INFO [CMS-c2|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = db-history-config-check (io.debezium.util.Threads:270)
[2022-11-16 12:12:06,920] INFO [CMS-c2|task-0] Idempotence will be disabled because acks is set to 1, not set to 'all'. (org.apache.kafka.clients.producer.ProducerConfig:501)
[2022-11-16 12:12:06,922] INFO [CMS-c2|task-0] ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9094]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:12:06,946] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:06,947] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:06,948] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668597126946 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:06,955] INFO [CMS-c2|task-0] [Producer clientId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:06,986] INFO [CMS-c2|task-0] Closing connection before starting schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:96)
[2022-11-16 12:12:06,989] INFO [CMS-c2|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:12:07,141] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:07,204] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:07,204] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:07,207] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668597127204 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:07,220] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:07,233] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:07,233] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:07,235] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:07,236] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:07,237] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:07,240] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:07,242] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:07,251] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:07,251] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:07,252] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668597127251 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:07,254] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-db-history-config-check (io.debezium.util.Threads:287)
[2022-11-16 12:12:07,257] INFO [CMS-c2|task-0] AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory-topic-check
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-16 12:12:07,266] WARN [CMS-c2|task-0] The configuration 'value.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:07,267] WARN [CMS-c2|task-0] The configuration 'batch.size' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:07,267] WARN [CMS-c2|task-0] The configuration 'max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:07,268] WARN [CMS-c2|task-0] The configuration 'acks' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:07,269] WARN [CMS-c2|task-0] The configuration 'buffer.memory' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:07,269] WARN [CMS-c2|task-0] The configuration 'key.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:07,270] WARN [CMS-c2|task-0] The configuration 'linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:07,271] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:07,272] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:07,272] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668597127271 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:07,425] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to ZYdk-d2NR5mwfg81KAWrBQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:12:07,427] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:07,452] INFO [CMS-c2|task-0] Database history topic 'schema-changes.inventory' has correct settings (io.debezium.relational.history.KafkaDatabaseHistory:444)
[2022-11-16 12:12:07,459] INFO [CMS-c2|task-0] App info kafka.admin.client for testdb-dbhistory-topic-check unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:07,463] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:07,464] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:07,468] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:07,480] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:07,480] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:07,486] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:07,487] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:07,488] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:07,493] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:07,495] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:07,510] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:07,510] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:07,511] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668597127510 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:07,521] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:07,533] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:07,534] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:07,536] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:07,537] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:07,540] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:07,547] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:07,549] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:07,566] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:07,567] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:07,569] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668597127566 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:07,581] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to ZYdk-d2NR5mwfg81KAWrBQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:12:07,581] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:07,597] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:07,598] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:07,599] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:07,601] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:07,601] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:07,604] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:07,606] INFO [CMS-c2|task-0] Started database history recovery (io.debezium.relational.history.DatabaseHistoryMetrics:113)
[2022-11-16 12:12:07,625] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:07,636] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:07,636] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:07,637] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668597127635 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:07,645] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Subscribed to topic(s): schema-changes.inventory (org.apache.kafka.clients.consumer.KafkaConsumer:968)
[2022-11-16 12:12:07,661] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to ZYdk-d2NR5mwfg81KAWrBQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:12:07,662] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:07,679] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Discovered group coordinator localhost:9094 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:884)
[2022-11-16 12:12:07,685] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:553)
[2022-11-16 12:12:07,720] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: need to re-join with the given member-id: testdb-dbhistory-1841f5e0-32a6-4a60-b386-d9a5ad23b663 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:07,721] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:07,724] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:553)
[2022-11-16 12:12:07,749] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Successfully joined group with generation Generation{generationId=1, memberId='testdb-dbhistory-1841f5e0-32a6-4a60-b386-d9a5ad23b663', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:614)
[2022-11-16 12:12:07,754] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Finished assignment for group at generation 1: {testdb-dbhistory-1841f5e0-32a6-4a60-b386-d9a5ad23b663=Assignment(partitions=[schema-changes.inventory-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:702)
[2022-11-16 12:12:07,794] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Successfully synced group in generation Generation{generationId=1, memberId='testdb-dbhistory-1841f5e0-32a6-4a60-b386-d9a5ad23b663', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:789)
[2022-11-16 12:12:07,797] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Notifying assignor about the new Assignment(partitions=[schema-changes.inventory-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:301)
[2022-11-16 12:12:07,806] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Adding newly assigned partitions: schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:313)
[2022-11-16 12:12:07,846] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Found no committed offset for partition schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1515)
[2022-11-16 12:12:07,883] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting offset for partition schema-changes.inventory-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9094 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2022-11-16 12:12:08,113] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Revoke previously assigned partitions schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:332)
[2022-11-16 12:12:08,119] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Member testdb-dbhistory-1841f5e0-32a6-4a60-b386-d9a5ad23b663 sending LeaveGroup request to coordinator localhost:9094 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1111)
[2022-11-16 12:12:08,123] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:08,126] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:08,152] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:08,152] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:08,159] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:08,162] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:08,163] INFO [CMS-c2|task-0] Finished database history recovery of 36 change(s) in 557 ms (io.debezium.relational.history.DatabaseHistoryMetrics:119)
[2022-11-16 12:12:08,166] INFO [CMS-c2|task-0] Reconnecting after finishing schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:110)
[2022-11-16 12:12:08,176] INFO [CMS-c2|task-0] Get all known binlogs from MySQL (io.debezium.connector.mysql.MySqlConnection:408)
[2022-11-16 12:12:08,180] INFO [CMS-c2|task-0] MySQL has the binlog file 'mysql-bin.000024' required by the connector (io.debezium.connector.mysql.MySqlConnectorTask:333)
[2022-11-16 12:12:08,228] INFO [CMS-c2|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2022-11-16 12:12:08,230] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-change-event-source-coordinator (io.debezium.util.Threads:287)
[2022-11-16 12:12:08,232] INFO [CMS-c2|task-0] WorkerSourceTask{id=CMS-c2-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:227)
[2022-11-16 12:12:08,239] INFO [CMS-c2|task-0] WorkerSourceTask{id=CMS-c2-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2022-11-16 12:12:08,241] INFO [CMS-c2|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:102)
[2022-11-16 12:12:08,243] INFO [CMS-c2|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:105)
[2022-11-16 12:12:08,253] INFO [CMS-c2|task-0] A previous offset indicating a completed snapshot has been found. Neither schema nor data will be snapshotted. (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:82)
[2022-11-16 12:12:08,256] INFO [CMS-c2|task-0] Snapshot ended with SnapshotResult [status=SKIPPED, offset=MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000024, currentBinlogPosition=2290, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000024, restartBinlogPosition=2290, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]] (io.debezium.pipeline.ChangeEventSourceCoordinator:154)
[2022-11-16 12:12:08,265] INFO [CMS-c2|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = binlog-client (io.debezium.util.Threads:270)
[2022-11-16 12:12:08,270] INFO [CMS-c2|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:171)
[2022-11-16 12:12:08,270] WARN [CMS-c2|task-0] After applying the include/exclude list filters, no changes will be captured. Please check your configuration! (io.debezium.relational.RelationalDatabaseSchema:85)
[2022-11-16 12:12:08,286] INFO [CMS-c2|task-0] Skip 2 events on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:914)
[2022-11-16 12:12:08,286] INFO [CMS-c2|task-0] Skip 1 rows on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:918)
[2022-11-16 12:12:08,288] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-16 12:12:08,295] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-16 12:12:08,312] INFO [CMS-c2|task-0] Connected to MySQL binlog at localhost:3306, starting at MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000024, currentBinlogPosition=2290, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000024, restartBinlogPosition=2290, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:1203)
[2022-11-16 12:12:08,313] INFO [CMS-c2|task-0] Waiting for keepalive thread to start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:935)
[2022-11-16 12:12:08,315] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-16 12:12:08,331] ERROR [CMS-c2|task-0] Encountered change event 'Event{header=EventHeaderV4{timestamp=1667341142000, eventType=TABLE_MAP, serverId=1, headerLength=19, dataLength=53, nextPosition=2450, flags=0}, data=TableMapEventData{tableId=95, database='testdb', table='lines_p', columnTypes=8, 15, 15, 18, 8, 15, columnMetadata=0, 1020, 1020, 0, 0, 1020, columnNullability={1, 2, 3, 4, 5}, eventMetadata=TableMapEventMetadata{signedness={}, defaultCharset=255, charsetCollations=null, columnCharsets=null, columnNames=null, setStrValues=null, enumStrValues=null, geometryTypes=null, simplePrimaryKeys=null, primaryKeysWithPrefix=null, enumAndSetDefaultCharset=null, enumAndSetColumnCharsets=null,visibility=null}}}' at offset {transaction_id=null, file=mysql-bin.000024, pos=2290, server_id=1, event=1} for table testdb.lines_p whose schema isn't known to this connector. One possible cause is an incomplete database history topic. Take a new snapshot in this case.
Use the mysqlbinlog tool to view the problematic event: mysqlbinlog --start-position=2378 --stop-position=2450 --verbose mysql-bin.000024 (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:649)
[2022-11-16 12:12:08,332] ERROR [CMS-c2|task-0] Error during binlog processing. Last offset stored = {transaction_id=null, file=mysql-bin.000024, pos=2290, server_id=104, event=1}, binlog reader near position = mysql-bin.000024/2378 (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:1072)
[2022-11-16 12:12:08,334] ERROR [CMS-c2|task-0] Producer failure (io.debezium.pipeline.ErrorHandler:31)
io.debezium.DebeziumException: Error processing binlog event
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleEvent(MySqlStreamingChangeEventSource.java:369)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.lambda$execute$25(MySqlStreamingChangeEventSource.java:860)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.notifyEventListeners(BinaryLogClient.java:1125)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:973)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:599)
	at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:857)
	at java.lang.Thread.run(Unknown Source)
Caused by: io.debezium.DebeziumException: Encountered change event for table testdb.lines_p whose schema isn't known to this connector
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.informAboutUnknownTableIfRequired(MySqlStreamingChangeEventSource.java:654)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleUpdateTableMetadata(MySqlStreamingChangeEventSource.java:633)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.lambda$execute$13(MySqlStreamingChangeEventSource.java:831)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleEvent(MySqlStreamingChangeEventSource.java:349)
	... 6 more
[2022-11-16 12:12:08,339] INFO [CMS-c2|task-0] Error processing binlog event, and propagating to Kafka Connect so it stops this connector. Future binlog events read before connector is shutdown will be ignored. (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:374)
[2022-11-16 12:12:08,419] INFO [CMS-c2|task-0] Keepalive thread is running (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:942)
[2022-11-16 12:12:08,750] ERROR [CMS-c2|task-0] WorkerSourceTask{id=CMS-c2-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:195)
org.apache.kafka.connect.errors.ConnectException: An exception occurred in the change event producer. This connector will be stopped.
	at io.debezium.pipeline.ErrorHandler.setProducerThrowable(ErrorHandler.java:42)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleEvent(MySqlStreamingChangeEventSource.java:369)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.lambda$execute$25(MySqlStreamingChangeEventSource.java:860)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.notifyEventListeners(BinaryLogClient.java:1125)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:973)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:599)
	at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:857)
	at java.lang.Thread.run(Unknown Source)
Caused by: io.debezium.DebeziumException: Error processing binlog event
	... 7 more
Caused by: io.debezium.DebeziumException: Encountered change event for table testdb.lines_p whose schema isn't known to this connector
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.informAboutUnknownTableIfRequired(MySqlStreamingChangeEventSource.java:654)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleUpdateTableMetadata(MySqlStreamingChangeEventSource.java:633)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.lambda$execute$13(MySqlStreamingChangeEventSource.java:831)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleEvent(MySqlStreamingChangeEventSource.java:349)
	... 6 more
[2022-11-16 12:12:08,753] INFO [CMS-c2|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:238)
[2022-11-16 12:12:08,872] INFO [CMS-c2|task-0] Finished streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:173)
[2022-11-16 12:12:08,873] INFO [CMS-c2|task-0] Stopped reading binlog after 0 events, last recorded offset: {transaction_id=null, file=mysql-bin.000029, pos=4, server_id=1, event=13} (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:1188)
[2022-11-16 12:12:08,877] INFO [CMS-c2|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:12:08,881] INFO [CMS-c2|task-0] [Producer clientId=testdb-dbhistory] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1249)
[2022-11-16 12:12:08,885] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:08,885] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:08,886] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:08,890] INFO [CMS-c2|task-0] App info kafka.producer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:08,893] INFO [CMS-c2|task-0] [Producer clientId=connector-producer-CMS-c2-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1249)
[2022-11-16 12:12:08,897] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:08,897] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:08,898] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:08,900] INFO [CMS-c2|task-0] App info kafka.producer for connector-producer-CMS-c2-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:27,377] INFO Successfully tested connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useSSL=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'dbz' (io.debezium.connector.mysql.MySqlConnector:100)
[2022-11-16 12:12:27,382] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:12:27,384] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2022-11-16 12:12:27,389] INFO [CMS-connecto r5|worker] Creating connector CMS-connecto r5 of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:264)
[2022-11-16 12:12:27,390] INFO [CMS-connecto r5|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:12:27,392] INFO [CMS-connecto r5|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:12:27,396] INFO [CMS-connecto r5|worker] Instantiated connector CMS-connecto r5 with version 1.8.0.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:274)
[2022-11-16 12:12:27,397] INFO [CMS-connecto r5|worker] Finished creating connector CMS-connecto r5 (org.apache.kafka.connect.runtime.Worker:299)
[2022-11-16 12:12:27,398] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:12:27,399] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:12:27,405] INFO [CMS-connecto r5|task-0] Creating task CMS-connecto r5-0 (org.apache.kafka.connect.runtime.Worker:498)
[2022-11-16 12:12:27,408] INFO [CMS-connecto r5|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2022-11-16 12:12:27,411] INFO [CMS-connecto r5|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:12:27,411] INFO [CMS-connecto r5|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2022-11-16 12:12:27,412] INFO [CMS-connecto r5|task-0] Instantiated task CMS-connecto r5-0 with version 1.8.0.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:513)
[2022-11-16 12:12:27,413] INFO [CMS-connecto r5|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:12:27,414] INFO [CMS-connecto r5|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task CMS-connecto r5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:526)
[2022-11-16 12:12:27,415] INFO [CMS-connecto r5|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-16 12:12:27,415] INFO [CMS-connecto r5|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task CMS-connecto r5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:532)
[2022-11-16 12:12:27,416] INFO [CMS-connecto r5|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task CMS-connecto r5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-11-16 12:12:27,421] INFO [CMS-connecto r5|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-16 12:12:27,423] INFO [CMS-connecto r5|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto r5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-16 12:12:27,426] INFO [CMS-connecto r5|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:593)
[2022-11-16 12:12:27,428] INFO [CMS-connecto r5|task-0] ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-CMS-connecto r5-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:12:27,438] WARN [CMS-connecto r5|task-0] The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:384)
[2022-11-16 12:12:27,441] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:27,442] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:27,443] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668597147441 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:27,463] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:27,472] INFO [CMS-connecto r5|task-0] Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:124)
[2022-11-16 12:12:27,474] INFO [CMS-connecto r5|task-0]    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,474] INFO [CMS-connecto r5|task-0]    database.user = dbz (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,475] INFO [CMS-connecto r5|task-0]    config.storage.topic = my_connect_config (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,476] INFO [CMS-connecto r5|task-0]    database.server.id = 14404 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,477] INFO [CMS-connecto r5|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,478] INFO [CMS-connecto r5|task-0]    database.history.kafka.bootstrap.servers = localhost:9094 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,479] INFO [CMS-connecto r5|task-0]    database.history.kafka.topic = schema-changes.inventory (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,480] INFO [CMS-connecto r5|task-0]    status.storage.topic = my_connect_statuses (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,481] INFO [CMS-connecto r5|task-0]    database.server.name = testdb (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,482] INFO [CMS-connecto r5|task-0]    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,484] INFO [CMS-connecto r5|task-0]    heartbeat.interval?.ms = 5000 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,492] INFO [CMS-connecto r5|task-0]    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,493] INFO [CMS-connecto r5|task-0]    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,494] INFO [CMS-connecto r5|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,495] INFO [CMS-connecto r5|task-0]    name = CMS-connecto r5 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,499] INFO [CMS-connecto r5|task-0]    offset.storage.topic = my_connect_offsets (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-16 12:12:27,543] INFO [CMS-connecto r5|task-0] Found previous partition offset io.debezium.connector.mysql.MySqlPartition@cbb77490: MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000029, currentBinlogPosition=156, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000029, restartBinlogPosition=156, restartRowsToSkip=0, restartEventsToSkip=0, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.common.BaseSourceTask:313)
[2022-11-16 12:12:27,559] INFO [CMS-connecto r5|task-0] KafkaDatabaseHistory Consumer config: {enable.auto.commit=false, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, group.id=testdb-dbhistory, auto.offset.reset=earliest, session.timeout.ms=10000, bootstrap.servers=localhost:9094, client.id=testdb-dbhistory, key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, fetch.min.bytes=1} (io.debezium.relational.history.KafkaDatabaseHistory:219)
[2022-11-16 12:12:27,559] INFO [CMS-connecto r5|task-0] KafkaDatabaseHistory Producer config: {bootstrap.servers=localhost:9094, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=1048576, retries=1, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=testdb-dbhistory, linger.ms=0, batch.size=32768, max.block.ms=10000, acks=1} (io.debezium.relational.history.KafkaDatabaseHistory:220)
[2022-11-16 12:12:27,560] INFO [CMS-connecto r5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = db-history-config-check (io.debezium.util.Threads:270)
[2022-11-16 12:12:27,561] INFO [CMS-connecto r5|task-0] Idempotence will be disabled because acks is set to 1, not set to 'all'. (org.apache.kafka.clients.producer.ProducerConfig:501)
[2022-11-16 12:12:27,565] INFO [CMS-connecto r5|task-0] ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9094]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-16 12:12:27,575] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:27,575] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:27,580] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668597147575 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:27,581] INFO [CMS-connecto r5|task-0] Closing connection before starting schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:96)
[2022-11-16 12:12:27,583] INFO [CMS-connecto r5|task-0] [Producer clientId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:27,586] INFO [CMS-connecto r5|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-16 12:12:27,588] INFO [CMS-connecto r5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:27,595] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:27,596] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:27,596] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668597147595 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:27,606] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:27,612] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:27,613] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:27,614] INFO [CMS-connecto r5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:27,616] INFO [CMS-connecto r5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:27,617] INFO [CMS-connecto r5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:27,621] INFO [CMS-connecto r5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:27,623] INFO [CMS-connecto r5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:27,631] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:27,631] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:27,632] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668597147631 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:27,633] INFO [CMS-connecto r5|task-0] Creating thread debezium-mysqlconnector-testdb-db-history-config-check (io.debezium.util.Threads:287)
[2022-11-16 12:12:27,638] INFO [CMS-connecto r5|task-0] AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory-topic-check
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-16 12:12:27,643] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to ZYdk-d2NR5mwfg81KAWrBQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:12:27,645] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:27,658] WARN [CMS-connecto r5|task-0] The configuration 'value.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,663] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:27,664] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:27,666] INFO [CMS-connecto r5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:27,666] INFO [CMS-connecto r5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:27,667] INFO [CMS-connecto r5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:27,664] WARN [CMS-connecto r5|task-0] The configuration 'batch.size' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,673] INFO [CMS-connecto r5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:27,674] WARN [CMS-connecto r5|task-0] The configuration 'max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,675] INFO [CMS-connecto r5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:27,675] WARN [CMS-connecto r5|task-0] The configuration 'acks' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,678] WARN [CMS-connecto r5|task-0] The configuration 'buffer.memory' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,680] WARN [CMS-connecto r5|task-0] The configuration 'key.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,683] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:27,684] WARN [CMS-connecto r5|task-0] The configuration 'linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,691] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:27,693] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668597147683 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:27,694] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:27,696] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:27,700] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668597147692 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:27,701] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:27,711] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:27,714] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:27,714] INFO [CMS-connecto r5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:27,715] INFO [CMS-connecto r5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:27,726] INFO [CMS-connecto r5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:27,730] INFO [CMS-connecto r5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:27,731] INFO [CMS-connecto r5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:27,740] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:27,740] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:27,741] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668597147740 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:27,746] INFO [CMS-connecto r5|task-0] Database history topic 'schema-changes.inventory' has correct settings (io.debezium.relational.history.KafkaDatabaseHistory:444)
[2022-11-16 12:12:27,747] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to ZYdk-d2NR5mwfg81KAWrBQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:12:27,750] INFO [CMS-connecto r5|task-0] App info kafka.admin.client for testdb-dbhistory-topic-check unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:27,750] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:27,754] INFO [CMS-connecto r5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:27,755] INFO [CMS-connecto r5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:27,756] INFO [CMS-connecto r5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:27,759] INFO [CMS-connecto r5|task-0] AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory-topic-check
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-16 12:12:27,764] WARN [CMS-connecto r5|task-0] The configuration 'value.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,765] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:27,767] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:27,766] WARN [CMS-connecto r5|task-0] The configuration 'batch.size' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,768] INFO [CMS-connecto r5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:27,771] WARN [CMS-connecto r5|task-0] The configuration 'max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,771] INFO [CMS-connecto r5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:27,772] INFO [CMS-connecto r5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:27,772] WARN [CMS-connecto r5|task-0] The configuration 'acks' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,774] WARN [CMS-connecto r5|task-0] The configuration 'buffer.memory' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,775] WARN [CMS-connecto r5|task-0] The configuration 'key.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,775] WARN [CMS-connecto r5|task-0] The configuration 'linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-16 12:12:27,776] INFO [CMS-connecto r5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:27,780] INFO [CMS-connecto r5|task-0] Started database history recovery (io.debezium.relational.history.DatabaseHistoryMetrics:113)
[2022-11-16 12:12:27,781] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:27,782] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:27,783] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668597147776 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:27,783] INFO [CMS-connecto r5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-16 12:12:27,795] INFO [CMS-connecto r5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-16 12:12:27,800] INFO [CMS-connecto r5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-16 12:12:27,804] INFO [CMS-connecto r5|task-0] Kafka startTimeMs: 1668597147795 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-16 12:12:27,806] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Subscribed to topic(s): schema-changes.inventory (org.apache.kafka.clients.consumer.KafkaConsumer:968)
[2022-11-16 12:12:27,823] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to ZYdk-d2NR5mwfg81KAWrBQ (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:12:27,823] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: LqL9YrMQR021_XcBs9rDNg (org.apache.kafka.clients.Metadata:287)
[2022-11-16 12:12:27,839] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Discovered group coordinator localhost:9094 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:884)
[2022-11-16 12:12:27,841] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:553)
[2022-11-16 12:12:27,857] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: need to re-join with the given member-id: testdb-dbhistory-f36d2e54-9d03-4844-8877-107940e25290 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:27,858] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:27,863] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:553)
[2022-11-16 12:12:27,869] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Successfully joined group with generation Generation{generationId=3, memberId='testdb-dbhistory-f36d2e54-9d03-4844-8877-107940e25290', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:614)
[2022-11-16 12:12:27,873] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Finished assignment for group at generation 3: {testdb-dbhistory-f36d2e54-9d03-4844-8877-107940e25290=Assignment(partitions=[schema-changes.inventory-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:702)
[2022-11-16 12:12:27,924] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Successfully synced group in generation Generation{generationId=3, memberId='testdb-dbhistory-f36d2e54-9d03-4844-8877-107940e25290', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:789)
[2022-11-16 12:12:27,925] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Notifying assignor about the new Assignment(partitions=[schema-changes.inventory-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:301)
[2022-11-16 12:12:27,927] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Adding newly assigned partitions: schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:313)
[2022-11-16 12:12:27,926] INFO [CMS-connecto r5|task-0] Database history topic 'schema-changes.inventory' has correct settings (io.debezium.relational.history.KafkaDatabaseHistory:444)
[2022-11-16 12:12:27,931] INFO [CMS-connecto r5|task-0] App info kafka.admin.client for testdb-dbhistory-topic-check unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:27,932] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Found no committed offset for partition schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1515)
[2022-11-16 12:12:27,933] INFO [CMS-connecto r5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:27,938] INFO [CMS-connecto r5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:27,939] INFO [CMS-connecto r5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:27,940] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting offset for partition schema-changes.inventory-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9094 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2022-11-16 12:12:30,726] INFO [CMS-connecto r5|task-0] Database history recovery in progress, recovered 2 records (io.debezium.relational.history.DatabaseHistoryMetrics:127)
[2022-11-16 12:12:31,278] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Revoke previously assigned partitions schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:332)
[2022-11-16 12:12:31,281] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Member testdb-dbhistory-f36d2e54-9d03-4844-8877-107940e25290 sending LeaveGroup request to coordinator localhost:9094 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1111)
[2022-11-16 12:12:31,289] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-16 12:12:31,290] INFO [CMS-connecto r5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-16 12:12:31,299] INFO [CMS-connecto r5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-16 12:12:31,300] INFO [CMS-connecto r5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-16 12:12:31,301] INFO [CMS-connecto r5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-16 12:12:31,305] INFO [CMS-connecto r5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-16 12:12:31,318] INFO [CMS-connecto r5|task-0] Finished database history recovery of 36 change(s) in 3538 ms (io.debezium.relational.history.DatabaseHistoryMetrics:119)
[2022-11-16 12:12:31,376] INFO [CMS-connecto r5|task-0] Reconnecting after finishing schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:110)
[2022-11-16 12:12:31,388] INFO [CMS-connecto r5|task-0] Get all known binlogs from MySQL (io.debezium.connector.mysql.MySqlConnection:408)
[2022-11-16 12:12:31,391] INFO [CMS-connecto r5|task-0] MySQL has the binlog file 'mysql-bin.000029' required by the connector (io.debezium.connector.mysql.MySqlConnectorTask:333)
[2022-11-16 12:12:31,392] INFO [CMS-connecto r5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2022-11-16 12:12:31,393] INFO [CMS-connecto r5|task-0] Creating thread debezium-mysqlconnector-testdb-change-event-source-coordinator (io.debezium.util.Threads:287)
[2022-11-16 12:12:31,394] INFO [CMS-connecto r5|task-0] WorkerSourceTask{id=CMS-connecto r5-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:227)
[2022-11-16 12:12:31,397] INFO [CMS-connecto r5|task-0] WorkerSourceTask{id=CMS-connecto r5-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2022-11-16 12:12:31,404] INFO [CMS-connecto r5|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:102)
[2022-11-16 12:12:31,406] INFO [CMS-connecto r5|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:105)
[2022-11-16 12:12:31,407] INFO [CMS-connecto r5|task-0] A previous offset indicating a completed snapshot has been found. Neither schema nor data will be snapshotted. (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:82)
[2022-11-16 12:12:31,408] INFO [CMS-connecto r5|task-0] Snapshot ended with SnapshotResult [status=SKIPPED, offset=MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000029, currentBinlogPosition=156, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000029, restartBinlogPosition=156, restartRowsToSkip=0, restartEventsToSkip=0, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]] (io.debezium.pipeline.ChangeEventSourceCoordinator:154)
[2022-11-16 12:12:31,411] INFO [CMS-connecto r5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = binlog-client (io.debezium.util.Threads:270)
[2022-11-16 12:12:31,413] INFO [CMS-connecto r5|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:171)
[2022-11-16 12:12:31,420] INFO [CMS-connecto r5|task-0] Skip 0 events on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:914)
[2022-11-16 12:12:31,421] INFO [CMS-connecto r5|task-0] Skip 0 rows on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:918)
[2022-11-16 12:12:31,424] INFO [CMS-connecto r5|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-16 12:12:31,428] INFO [CMS-connecto r5|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-16 12:12:31,436] INFO [CMS-connecto r5|task-0] Connected to MySQL binlog at localhost:3306, starting at MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000029, currentBinlogPosition=156, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000029, restartBinlogPosition=156, restartRowsToSkip=0, restartEventsToSkip=0, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:1203)
[2022-11-16 12:12:31,437] INFO [CMS-connecto r5|task-0] Waiting for keepalive thread to start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:935)
[2022-11-16 12:12:31,437] INFO [CMS-connecto r5|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-16 12:12:31,550] INFO [CMS-connecto r5|task-0] Keepalive thread is running (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:942)
[2022-11-16 12:12:31,926] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Resetting the last seen epoch of partition testdb.testdb.lines_p-0 to 0 since the associated topicId changed from null to dpg92B6dR0qdszr64wLUJg (org.apache.kafka.clients.Metadata:402)
[2022-11-16 12:21:27,527] INFO [CMS-connecto r5|task-0] [Producer clientId=connector-producer-CMS-connecto r5-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:935)
[2022-11-16 12:21:27,669] INFO [CMS-connecto r5|task-0] [Producer clientId=testdb-dbhistory] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:935)
