[2022-11-11 20:02:13,877] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-11-11 20:02:13,896] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=C:\Users\1s0\Desktop\kafka_2.12-3.2.1/logs, -Dlog4j.configuration=file:C:\Users\1s0\Desktop\kafka_2.12-3.2.1/config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_333, 25.333-b02
	jvm.classpath = C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\activation-1.1.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\argparse4j-0.7.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\audience-annotations-0.5.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\commons-cli-1.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\commons-lang3-3.8.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-api-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-basic-auth-extension-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-file-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-json-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-mirror-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-mirror-client-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-runtime-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\connect-transforms-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\hk2-api-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\hk2-locator-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\hk2-utils-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-annotations-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-core-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-databind-2.12.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-dataformat-csv-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-datatype-jdk8-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-jaxrs-base-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-jaxrs-json-provider-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-module-jaxb-annotations-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jackson-module-scala_2.12-2.12.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.activation-api-1.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.inject-2.6.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.validation-api-2.0.2.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\javassist-3.27.0-GA.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\javax.servlet-api-3.1.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jaxb-api-2.3.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-client-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-common-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-container-servlet-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-container-servlet-core-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-hk2-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jersey-server-2.34.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-client-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-continuation-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-http-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-io-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-security-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-server-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-servlet-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-servlets-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-util-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jetty-util-ajax-9.4.44.v20210927.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jline-3.21.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jopt-simple-5.0.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\jose4j-0.7.9.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-clients-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-log4j-appender-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-metadata-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-raft-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-server-common-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-shell-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-storage-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-storage-api-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-examples-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-scala_2.12-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-streams-test-utils-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka-tools-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\kafka_2.12-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\lz4-java-1.8.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\maven-artifact-3.8.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\metrics-core-2.2.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\metrics-core-4.1.12.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\MySqlConnector.class;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-buffer-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-codec-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-common-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-handler-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-resolver-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-tcnative-classes-2.0.46.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-classes-epoll-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-native-epoll-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\netty-transport-native-unix-common-4.1.73.Final.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\osgi-resource-locator-1.0.3.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\paranamer-2.8.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\plexus-utils-3.3.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\reflections-0.9.12.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\reload4j-1.2.19.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\rocksdbjni-6.29.4.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-collection-compat_2.12-2.6.0.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-java8-compat_2.12-1.0.2.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-library-2.12.15.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-logging_2.12-3.9.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\scala-reflect-2.12.15.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\slf4j-api-1.7.36.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\slf4j-reload4j-1.7.36.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\snappy-java-1.1.8.4.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\trogdor-3.2.1.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\zookeeper-3.6.3.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\zookeeper-jute-3.6.3.jar;C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs\zstd-jni-1.5.2-1.jar
	os.spec = Windows 10, amd64, 10.0
	os.vcpus = 4
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-11-11 20:02:13,918] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-11-11 20:02:14,013] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\bin (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:14,105] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/bin/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:14,105] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:14,107] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:14,107] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:14,118] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\config (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:14,214] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/config/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:14,215] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\debezium (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:16,401] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/debezium/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:16,408] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:16,415] INFO Added plugin 'io.debezium.converters.ByteBufferConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:16,419] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:16,421] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:16,422] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:16,424] INFO Added plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:16,425] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:16,426] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:16,448] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\libs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:16,489] WARN Plugin path contains both java archives and class files. Returning only the archives (org.apache.kafka.connect.runtime.isolation.PluginUtils:294)
[2022-11-11 20:02:22,559] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/libs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:22,559] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,563] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,563] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,564] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,565] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,566] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,567] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,569] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,569] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,570] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,571] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,572] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,574] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,575] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,576] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,576] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,578] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,578] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,580] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,581] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,582] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,583] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,585] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,588] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,589] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,590] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,591] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,593] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,596] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,597] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,598] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,599] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,600] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,603] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,604] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,605] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,606] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,607] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,608] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,609] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,613] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,617] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,618] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,619] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,620] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,621] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,622] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,623] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,624] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,624] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,625] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,626] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2022-11-11 20:02:22,628] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\licenses (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:22,681] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/licenses/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:22,681] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\logs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:22,820] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/logs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:22,821] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\serverdata (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:22,830] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/serverdata/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:22,832] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\site-docs (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:22,837] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/site-docs/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:22,838] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\tmp (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:22,842] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/tmp/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:22,843] INFO Loading plugin from: C:\Users\1s0\Desktop\kafka_2.12-3.2.1\zookeeper-data (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:277)
[2022-11-11 20:02:22,850] INFO Registered loader: PluginClassLoader{pluginLocation=file:/C:/Users/1s0/Desktop/kafka_2.12-3.2.1/zookeeper-data/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:25,171] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:299)
[2022-11-11 20:02:25,179] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,180] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,182] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,185] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,186] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,188] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,189] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,191] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,196] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,198] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,204] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,212] INFO Added aliases 'ByteBufferConverter' and 'ByteBuffer' to plugin 'io.debezium.converters.ByteBufferConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,216] INFO Added aliases 'CloudEventsConverter' and 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,218] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,219] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,220] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,222] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,225] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,226] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,228] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,229] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,231] INFO Added aliases 'ByteBufferConverter' and 'ByteBuffer' to plugin 'io.debezium.converters.ByteBufferConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,232] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,233] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,234] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,235] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,237] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,237] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,241] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,242] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,244] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,246] INFO Added alias 'ReadToInsertEvent' to plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,248] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,249] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,250] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,252] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,253] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,257] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,259] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,263] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,268] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,272] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,274] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,276] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,277] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,279] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,281] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:473)
[2022-11-11 20:02:25,282] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,283] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,284] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:476)
[2022-11-11 20:02:25,344] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = All
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = mpconnect.offsets
	plugin.path = []
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:376)
[2022-11-11 20:02:25,350] WARN The worker has been configured with one or more internal converter properties ([internal.key.converter, schemas.enable, internal.value.converter, schemas.enable]). Support for these properties was deprecated in version 2.0 and removed in version 3.0, and specifying them will have no effect. Instead, an instance of the JsonConverter with schemas.enable set to false will be used. For more information, please visit http://kafka.apache.org/documentation/#upgrade and consult the upgrade notesfor the 3.0 release. (org.apache.kafka.connect.runtime.WorkerConfig:316)
[2022-11-11 20:02:25,355] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:51)
[2022-11-11 20:02:25,367] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-11 20:02:25,645] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,648] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,649] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,651] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,653] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,654] WARN The configuration 'file' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,655] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,666] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,667] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,668] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,672] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,674] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:25,680] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:25,682] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:25,688] INFO Kafka startTimeMs: 1668193345679 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:26,898] INFO Kafka cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.connect.util.ConnectUtils:67)
[2022-11-11 20:02:26,903] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:02:27,165] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:27,166] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:27,169] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:27,201] INFO Logging initialized @14818ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-11-11 20:02:28,145] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:117)
[2022-11-11 20:02:28,146] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:188)
[2022-11-11 20:02:28,190] INFO jetty-9.4.44.v20210927; built: 2021-09-27T23:02:44.612Z; git: 8da83308eeca865e495e53ef315a249d63ba9332; jvm 1.8.0_333-b02 (org.eclipse.jetty.server.Server:375)
[2022-11-11 20:02:28,322] INFO Started http_8083@3672276e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-11-11 20:02:28,324] INFO Started @15942ms (org.eclipse.jetty.server.Server:415)
[2022-11-11 20:02:28,393] INFO Advertised URI: http://192.168.1.43:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:355)
[2022-11-11 20:02:28,395] INFO REST server listening at http://192.168.1.43:8083/, advertising URL http://192.168.1.43:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2022-11-11 20:02:28,397] INFO Advertised URI: http://192.168.1.43:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:355)
[2022-11-11 20:02:28,398] INFO REST admin endpoints at http://192.168.1.43:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-11-11 20:02:28,400] INFO Advertised URI: http://192.168.1.43:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:355)
[2022-11-11 20:02:28,402] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2022-11-11 20:02:28,423] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:51)
[2022-11-11 20:02:28,425] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-11 20:02:28,482] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,487] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,492] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,502] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,509] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,518] WARN The configuration 'file' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,532] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,547] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,550] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,554] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,557] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,563] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:28,569] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:28,570] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:28,573] INFO Kafka startTimeMs: 1668193348569 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:28,629] INFO Kafka cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.connect.util.ConnectUtils:67)
[2022-11-11 20:02:28,634] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:02:28,656] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:28,664] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:28,670] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:28,686] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:28,704] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:28,731] INFO Kafka startTimeMs: 1668193348686 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:29,166] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-11 20:02:29,170] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-11 20:02:29,190] INFO Kafka Connect standalone worker initialization took 15306ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-11-11 20:02:29,190] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-11-11 20:02:29,194] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:98)
[2022-11-11 20:02:29,195] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2022-11-11 20:02:29,198] INFO Starting FileOffsetBackingStore with file mpconnect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-11-11 20:02:29,336] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2022-11-11 20:02:29,336] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:101)
[2022-11-11 20:02:29,338] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:208)
[2022-11-11 20:02:29,443] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:225)
[2022-11-11 20:02:29,679] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-11-11 20:02:29,679] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-11-11 20:02:29,684] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2022-11-11 20:02:31,869] INFO Started o.e.j.s.ServletContextHandler@53311681{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-11-11 20:02:31,870] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:303)
[2022-11-11 20:02:31,871] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-11-11 20:02:32,706] INFO Successfully tested connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useSSL=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'dbz' (io.debezium.connector.mysql.MySqlConnector:100)
[2022-11-11 20:02:32,731] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-11 20:02:32,756] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2022-11-11 20:02:32,776] INFO [CMS-c2|worker] Creating connector CMS-c2 of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:264)
[2022-11-11 20:02:32,779] INFO [CMS-c2|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-11 20:02:32,781] INFO [CMS-c2|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-11 20:02:32,794] INFO [CMS-c2|worker] Instantiated connector CMS-c2 with version 1.8.0.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:274)
[2022-11-11 20:02:32,795] INFO [CMS-c2|worker] Finished creating connector CMS-c2 (org.apache.kafka.connect.runtime.Worker:299)
[2022-11-11 20:02:32,802] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-11 20:02:32,803] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-11 20:02:32,810] INFO [CMS-c2|task-0] Creating task CMS-c2-0 (org.apache.kafka.connect.runtime.Worker:498)
[2022-11-11 20:02:32,819] INFO [CMS-c2|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2022-11-11 20:02:32,823] INFO [CMS-c2|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-11 20:02:32,830] INFO [CMS-c2|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2022-11-11 20:02:32,833] INFO [CMS-c2|task-0] Instantiated task CMS-c2-0 with version 1.8.0.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:513)
[2022-11-11 20:02:32,837] INFO [CMS-c2|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-11 20:02:32,840] INFO [CMS-c2|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task CMS-c2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:526)
[2022-11-11 20:02:32,842] INFO [CMS-c2|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-11 20:02:32,843] INFO [CMS-c2|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task CMS-c2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:532)
[2022-11-11 20:02:32,845] INFO [CMS-c2|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task CMS-c2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-11-11 20:02:32,855] INFO [CMS-c2|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-11 20:02:32,857] INFO [CMS-c2|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-c2
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-11 20:02:32,862] INFO [CMS-c2|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:593)
[2022-11-11 20:02:32,879] INFO [CMS-c2|task-0] ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-CMS-c2-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-11 20:02:32,966] WARN [CMS-c2|task-0] The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:384)
[2022-11-11 20:02:32,969] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:32,980] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:32,998] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668193352969 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:33,052] INFO Created connector CMS-c2 (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-11-11 20:02:33,054] INFO [CMS-c2|task-0] [Producer clientId=connector-producer-CMS-c2-0] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:02:33,064] INFO [CMS-c2|task-0] Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:124)
[2022-11-11 20:02:33,067] INFO [CMS-c2|task-0]    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,068] INFO [CMS-c2|task-0]    database.user = dbz (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,069] INFO [CMS-c2|task-0]    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,070] INFO [CMS-c2|task-0]    database.server.id = 111113 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,071] INFO [CMS-c2|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,072] INFO [CMS-c2|task-0]    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,074] INFO [CMS-c2|task-0]    database.history.kafka.bootstrap.servers = localhost:9094 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,077] INFO [CMS-c2|task-0]    database.history.kafka.topic = schema-changes.inventory (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,078] INFO [CMS-c2|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,081] INFO [CMS-c2|task-0]    name = CMS-c2 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,081] INFO [CMS-c2|task-0]    database.server.name = testdb (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,082] INFO [CMS-c2|task-0]    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:02:33,301] INFO [CMS-c2|task-0] Found previous partition offset io.debezium.connector.mysql.MySqlPartition@cbb77490: MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000024, currentBinlogPosition=2290, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000024, restartBinlogPosition=2290, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.common.BaseSourceTask:313)
[2022-11-11 20:02:33,387] INFO [CMS-c2|task-0] KafkaDatabaseHistory Consumer config: {enable.auto.commit=false, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, group.id=testdb-dbhistory, auto.offset.reset=earliest, session.timeout.ms=10000, bootstrap.servers=localhost:9094, client.id=testdb-dbhistory, key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, fetch.min.bytes=1} (io.debezium.relational.history.KafkaDatabaseHistory:219)
[2022-11-11 20:02:33,388] INFO [CMS-c2|task-0] KafkaDatabaseHistory Producer config: {bootstrap.servers=localhost:9094, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=1048576, retries=1, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=testdb-dbhistory, linger.ms=0, batch.size=32768, max.block.ms=10000, acks=1} (io.debezium.relational.history.KafkaDatabaseHistory:220)
[2022-11-11 20:02:33,391] INFO [CMS-c2|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = db-history-config-check (io.debezium.util.Threads:270)
[2022-11-11 20:02:33,396] INFO [CMS-c2|task-0] Idempotence will be disabled because acks is set to 1, not set to 'all'. (org.apache.kafka.clients.producer.ProducerConfig:501)
[2022-11-11 20:02:33,397] INFO [CMS-c2|task-0] ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9094]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-11 20:02:33,410] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:33,416] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:33,416] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668193353410 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:33,430] INFO [CMS-c2|task-0] [Producer clientId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:02:33,472] INFO [CMS-c2|task-0] Closing connection before starting schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:96)
[2022-11-11 20:02:33,476] INFO [CMS-c2|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-11 20:02:33,504] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:02:33,609] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:33,610] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:33,611] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668193353609 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:33,640] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:02:33,681] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:02:33,683] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:02:33,690] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:33,692] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:33,695] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:33,701] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:02:33,705] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:02:33,722] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:33,725] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:33,728] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668193353722 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:33,731] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-db-history-config-check (io.debezium.util.Threads:287)
[2022-11-11 20:02:33,735] INFO [CMS-c2|task-0] AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory-topic-check
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-11 20:02:33,749] WARN [CMS-c2|task-0] The configuration 'value.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:33,750] WARN [CMS-c2|task-0] The configuration 'batch.size' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:33,755] WARN [CMS-c2|task-0] The configuration 'max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:33,756] WARN [CMS-c2|task-0] The configuration 'acks' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:33,756] WARN [CMS-c2|task-0] The configuration 'buffer.memory' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:33,757] WARN [CMS-c2|task-0] The configuration 'key.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:33,758] WARN [CMS-c2|task-0] The configuration 'linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:02:33,760] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:33,761] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:33,762] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668193353760 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:33,805] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to Y5YhC3nSSyCom-dQQb7uYQ (org.apache.kafka.clients.Metadata:402)
[2022-11-11 20:02:33,807] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:02:33,893] INFO [CMS-c2|task-0] Database history topic 'schema-changes.inventory' has correct settings (io.debezium.relational.history.KafkaDatabaseHistory:444)
[2022-11-11 20:02:33,935] INFO [CMS-c2|task-0] App info kafka.admin.client for testdb-dbhistory-topic-check unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:02:33,939] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:33,945] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:33,947] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:33,958] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:02:33,959] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:02:33,970] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:33,970] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:33,971] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:33,979] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:02:33,982] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:02:34,007] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:34,008] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:34,010] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668193354007 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:34,067] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:02:34,099] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:02:34,100] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:02:34,103] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:34,104] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:34,106] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:34,123] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:02:34,129] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:02:34,147] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:34,147] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:34,149] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668193354145 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:34,158] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to Y5YhC3nSSyCom-dQQb7uYQ (org.apache.kafka.clients.Metadata:402)
[2022-11-11 20:02:34,158] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:02:34,170] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:02:34,171] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:02:34,173] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:34,173] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:34,177] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:34,182] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:02:34,183] INFO [CMS-c2|task-0] Started database history recovery (io.debezium.relational.history.DatabaseHistoryMetrics:113)
[2022-11-11 20:02:34,204] INFO [CMS-c2|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:02:34,230] INFO [CMS-c2|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:02:34,231] INFO [CMS-c2|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:02:34,232] INFO [CMS-c2|task-0] Kafka startTimeMs: 1668193354230 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:02:34,234] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Subscribed to topic(s): schema-changes.inventory (org.apache.kafka.clients.consumer.KafkaConsumer:968)
[2022-11-11 20:02:34,249] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to Y5YhC3nSSyCom-dQQb7uYQ (org.apache.kafka.clients.Metadata:402)
[2022-11-11 20:02:34,249] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:02:34,275] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Discovered group coordinator localhost:9094 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:884)
[2022-11-11 20:02:34,281] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:553)
[2022-11-11 20:02:34,326] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: need to re-join with the given member-id: testdb-dbhistory-38d3d5af-3a8e-469c-bb9c-c7b4c0536814 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:02:34,326] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:02:34,329] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:553)
[2022-11-11 20:02:34,357] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Successfully joined group with generation Generation{generationId=1, memberId='testdb-dbhistory-38d3d5af-3a8e-469c-bb9c-c7b4c0536814', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:614)
[2022-11-11 20:02:34,361] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Finished assignment for group at generation 1: {testdb-dbhistory-38d3d5af-3a8e-469c-bb9c-c7b4c0536814=Assignment(partitions=[schema-changes.inventory-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:702)
[2022-11-11 20:02:34,405] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Successfully synced group in generation Generation{generationId=1, memberId='testdb-dbhistory-38d3d5af-3a8e-469c-bb9c-c7b4c0536814', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:789)
[2022-11-11 20:02:34,407] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Notifying assignor about the new Assignment(partitions=[schema-changes.inventory-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:301)
[2022-11-11 20:02:34,415] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Adding newly assigned partitions: schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:313)
[2022-11-11 20:02:34,442] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Found no committed offset for partition schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1515)
[2022-11-11 20:02:34,460] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting offset for partition schema-changes.inventory-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9094 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2022-11-11 20:02:34,632] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Revoke previously assigned partitions schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:332)
[2022-11-11 20:02:34,633] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Member testdb-dbhistory-38d3d5af-3a8e-469c-bb9c-c7b4c0536814 sending LeaveGroup request to coordinator localhost:9094 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1111)
[2022-11-11 20:02:34,636] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:02:34,637] INFO [CMS-c2|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:02:34,658] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:34,658] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:34,661] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:34,666] INFO [CMS-c2|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:02:34,666] INFO [CMS-c2|task-0] Finished database history recovery of 36 change(s) in 483 ms (io.debezium.relational.history.DatabaseHistoryMetrics:119)
[2022-11-11 20:02:34,669] INFO [CMS-c2|task-0] Reconnecting after finishing schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:110)
[2022-11-11 20:02:34,675] INFO [CMS-c2|task-0] Get all known binlogs from MySQL (io.debezium.connector.mysql.MySqlConnection:408)
[2022-11-11 20:02:35,448] INFO [CMS-c2|task-0] MySQL has the binlog file 'mysql-bin.000024' required by the connector (io.debezium.connector.mysql.MySqlConnectorTask:333)
[2022-11-11 20:02:35,491] INFO [CMS-c2|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2022-11-11 20:02:35,493] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-change-event-source-coordinator (io.debezium.util.Threads:287)
[2022-11-11 20:02:35,494] INFO [CMS-c2|task-0] WorkerSourceTask{id=CMS-c2-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:227)
[2022-11-11 20:02:35,498] INFO [CMS-c2|task-0] WorkerSourceTask{id=CMS-c2-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2022-11-11 20:02:35,504] INFO [CMS-c2|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:102)
[2022-11-11 20:02:35,505] INFO [CMS-c2|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:105)
[2022-11-11 20:02:35,515] INFO [CMS-c2|task-0] A previous offset indicating a completed snapshot has been found. Neither schema nor data will be snapshotted. (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:82)
[2022-11-11 20:02:35,517] INFO [CMS-c2|task-0] Snapshot ended with SnapshotResult [status=SKIPPED, offset=MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000024, currentBinlogPosition=2290, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000024, restartBinlogPosition=2290, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]] (io.debezium.pipeline.ChangeEventSourceCoordinator:154)
[2022-11-11 20:02:35,524] INFO [CMS-c2|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = binlog-client (io.debezium.util.Threads:270)
[2022-11-11 20:02:35,530] INFO [CMS-c2|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:171)
[2022-11-11 20:02:35,531] WARN [CMS-c2|task-0] After applying the include/exclude list filters, no changes will be captured. Please check your configuration! (io.debezium.relational.RelationalDatabaseSchema:85)
[2022-11-11 20:02:35,548] INFO [CMS-c2|task-0] Skip 2 events on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:914)
[2022-11-11 20:02:35,549] INFO [CMS-c2|task-0] Skip 1 rows on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:918)
[2022-11-11 20:02:35,551] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-11 20:02:35,556] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-11 20:02:35,603] INFO [CMS-c2|task-0] Connected to MySQL binlog at localhost:3306, starting at MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000024, currentBinlogPosition=2290, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000024, restartBinlogPosition=2290, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:1203)
[2022-11-11 20:02:35,605] INFO [CMS-c2|task-0] Waiting for keepalive thread to start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:935)
[2022-11-11 20:02:35,607] INFO [CMS-c2|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-11 20:02:35,624] ERROR [CMS-c2|task-0] Encountered change event 'Event{header=EventHeaderV4{timestamp=1667341142000, eventType=TABLE_MAP, serverId=1, headerLength=19, dataLength=53, nextPosition=2450, flags=0}, data=TableMapEventData{tableId=95, database='testdb', table='lines_p', columnTypes=8, 15, 15, 18, 8, 15, columnMetadata=0, 1020, 1020, 0, 0, 1020, columnNullability={1, 2, 3, 4, 5}, eventMetadata=TableMapEventMetadata{signedness={}, defaultCharset=255, charsetCollations=null, columnCharsets=null, columnNames=null, setStrValues=null, enumStrValues=null, geometryTypes=null, simplePrimaryKeys=null, primaryKeysWithPrefix=null, enumAndSetDefaultCharset=null, enumAndSetColumnCharsets=null,visibility=null}}}' at offset {transaction_id=null, file=mysql-bin.000024, pos=2290, server_id=1, event=1} for table testdb.lines_p whose schema isn't known to this connector. One possible cause is an incomplete database history topic. Take a new snapshot in this case.
Use the mysqlbinlog tool to view the problematic event: mysqlbinlog --start-position=2378 --stop-position=2450 --verbose mysql-bin.000024 (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:649)
[2022-11-11 20:02:35,625] ERROR [CMS-c2|task-0] Error during binlog processing. Last offset stored = {transaction_id=null, file=mysql-bin.000024, pos=2290, server_id=104, event=1}, binlog reader near position = mysql-bin.000024/2378 (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:1072)
[2022-11-11 20:02:35,628] ERROR [CMS-c2|task-0] Producer failure (io.debezium.pipeline.ErrorHandler:31)
io.debezium.DebeziumException: Error processing binlog event
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleEvent(MySqlStreamingChangeEventSource.java:369)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.lambda$execute$25(MySqlStreamingChangeEventSource.java:860)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.notifyEventListeners(BinaryLogClient.java:1125)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:973)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:599)
	at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:857)
	at java.lang.Thread.run(Unknown Source)
Caused by: io.debezium.DebeziumException: Encountered change event for table testdb.lines_p whose schema isn't known to this connector
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.informAboutUnknownTableIfRequired(MySqlStreamingChangeEventSource.java:654)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleUpdateTableMetadata(MySqlStreamingChangeEventSource.java:633)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.lambda$execute$13(MySqlStreamingChangeEventSource.java:831)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleEvent(MySqlStreamingChangeEventSource.java:349)
	... 6 more
[2022-11-11 20:02:35,650] INFO [CMS-c2|task-0] Error processing binlog event, and propagating to Kafka Connect so it stops this connector. Future binlog events read before connector is shutdown will be ignored. (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:374)
[2022-11-11 20:02:35,707] INFO [CMS-c2|task-0] Keepalive thread is running (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:942)
[2022-11-11 20:02:36,008] ERROR [CMS-c2|task-0] WorkerSourceTask{id=CMS-c2-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:195)
org.apache.kafka.connect.errors.ConnectException: An exception occurred in the change event producer. This connector will be stopped.
	at io.debezium.pipeline.ErrorHandler.setProducerThrowable(ErrorHandler.java:42)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleEvent(MySqlStreamingChangeEventSource.java:369)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.lambda$execute$25(MySqlStreamingChangeEventSource.java:860)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.notifyEventListeners(BinaryLogClient.java:1125)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:973)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:599)
	at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:857)
	at java.lang.Thread.run(Unknown Source)
Caused by: io.debezium.DebeziumException: Error processing binlog event
	... 7 more
Caused by: io.debezium.DebeziumException: Encountered change event for table testdb.lines_p whose schema isn't known to this connector
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.informAboutUnknownTableIfRequired(MySqlStreamingChangeEventSource.java:654)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleUpdateTableMetadata(MySqlStreamingChangeEventSource.java:633)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.lambda$execute$13(MySqlStreamingChangeEventSource.java:831)
	at io.debezium.connector.mysql.MySqlStreamingChangeEventSource.handleEvent(MySqlStreamingChangeEventSource.java:349)
	... 6 more
[2022-11-11 20:02:36,009] INFO [CMS-c2|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:238)
[2022-11-11 20:02:36,062] INFO [CMS-c2|task-0] Finished streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:173)
[2022-11-11 20:02:36,063] INFO [CMS-c2|task-0] Stopped reading binlog after 0 events, last recorded offset: {transaction_id=null, file=mysql-bin.000027, pos=4, server_id=1, event=3} (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:1188)
[2022-11-11 20:02:36,066] INFO [CMS-c2|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-11 20:02:36,070] INFO [CMS-c2|task-0] [Producer clientId=testdb-dbhistory] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1249)
[2022-11-11 20:02:36,073] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:36,073] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:36,074] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:36,075] INFO [CMS-c2|task-0] App info kafka.producer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:02:36,077] INFO [CMS-c2|task-0] [Producer clientId=connector-producer-CMS-c2-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1249)
[2022-11-11 20:02:36,082] INFO [CMS-c2|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:02:36,082] INFO [CMS-c2|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:02:36,083] INFO [CMS-c2|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:02:36,084] INFO [CMS-c2|task-0] App info kafka.producer for connector-producer-CMS-c2-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:03:07,610] INFO Successfully tested connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useSSL=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'dbz' (io.debezium.connector.mysql.MySqlConnector:100)
[2022-11-11 20:03:07,625] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-11 20:03:07,627] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2022-11-11 20:03:07,634] INFO [CMS-connecto5|worker] Creating connector CMS-connecto5 of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:264)
[2022-11-11 20:03:07,639] INFO [CMS-connecto5|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-11 20:03:07,645] INFO [CMS-connecto5|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-11 20:03:07,657] INFO [CMS-connecto5|worker] Instantiated connector CMS-connecto5 with version 1.8.0.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:274)
[2022-11-11 20:03:07,657] INFO [CMS-connecto5|worker] Finished creating connector CMS-connecto5 (org.apache.kafka.connect.runtime.Worker:299)
[2022-11-11 20:03:07,660] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-11 20:03:07,661] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-11 20:03:07,663] INFO [CMS-connecto5|task-0] Creating task CMS-connecto5-0 (org.apache.kafka.connect.runtime.Worker:498)
[2022-11-11 20:03:07,665] INFO [CMS-connecto5|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto5
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2022-11-11 20:03:07,667] INFO [CMS-connecto5|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto5
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-11 20:03:07,668] INFO [CMS-connecto5|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2022-11-11 20:03:07,668] INFO [CMS-connecto5|task-0] Instantiated task CMS-connecto5-0 with version 1.8.0.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:513)
[2022-11-11 20:03:07,673] INFO [CMS-connecto5|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-11 20:03:07,677] INFO [CMS-connecto5|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task CMS-connecto5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:526)
[2022-11-11 20:03:07,679] INFO [CMS-connecto5|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2022-11-11 20:03:07,680] INFO [CMS-connecto5|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task CMS-connecto5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:532)
[2022-11-11 20:03:07,681] INFO [CMS-connecto5|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task CMS-connecto5-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-11-11 20:03:07,683] INFO [CMS-connecto5|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:376)
[2022-11-11 20:03:07,685] INFO [CMS-connecto5|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = CMS-connecto5
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2022-11-11 20:03:07,686] INFO [CMS-connecto5|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:593)
[2022-11-11 20:03:07,691] INFO [CMS-connecto5|task-0] ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-CMS-connecto5-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-11 20:03:07,712] WARN [CMS-connecto5|task-0] The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:384)
[2022-11-11 20:03:07,713] INFO [CMS-connecto5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:03:07,715] INFO [CMS-connecto5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:03:07,716] INFO [CMS-connecto5|task-0] Kafka startTimeMs: 1668193387712 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:03:07,751] INFO [CMS-connecto5|task-0] [Producer clientId=connector-producer-CMS-connecto5-0] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:03:07,759] INFO [CMS-connecto5|task-0] Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:124)
[2022-11-11 20:03:07,785] INFO [CMS-connecto5|task-0]    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,801] INFO [CMS-connecto5|task-0]    database.user = dbz (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,810] INFO [CMS-connecto5|task-0]    config.storage.topic = my_connect_config (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,828] INFO [CMS-connecto5|task-0]    database.server.id = 144 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,833] INFO [CMS-connecto5|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,835] INFO [CMS-connecto5|task-0]    database.history.kafka.bootstrap.servers = localhost:9094 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,836] INFO [CMS-connecto5|task-0]    database.history.kafka.topic = schema-changes.inventory (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,839] INFO [CMS-connecto5|task-0]    status.storage.topic = my_connect_statuses (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,842] INFO [CMS-connecto5|task-0]    database.server.name = testdb (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,844] INFO [CMS-connecto5|task-0]    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,846] INFO [CMS-connecto5|task-0]    heartbeat.interval?.ms = 5000 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,848] INFO [CMS-connecto5|task-0]    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,849] INFO [CMS-connecto5|task-0]    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,850] INFO [CMS-connecto5|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,851] INFO [CMS-connecto5|task-0]    name = CMS-connecto5 (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,859] INFO [CMS-connecto5|task-0]    offset.storage.topic = my_connect_offsets (io.debezium.connector.common.BaseSourceTask:126)
[2022-11-11 20:03:07,909] INFO [CMS-connecto5|task-0] Found previous partition offset io.debezium.connector.mysql.MySqlPartition@cbb77490: MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000026, currentBinlogPosition=2887, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000026, restartBinlogPosition=2887, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.common.BaseSourceTask:313)
[2022-11-11 20:03:07,925] INFO [CMS-connecto5|task-0] KafkaDatabaseHistory Consumer config: {enable.auto.commit=false, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, group.id=testdb-dbhistory, auto.offset.reset=earliest, session.timeout.ms=10000, bootstrap.servers=localhost:9094, client.id=testdb-dbhistory, key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, fetch.min.bytes=1} (io.debezium.relational.history.KafkaDatabaseHistory:219)
[2022-11-11 20:03:07,942] INFO [CMS-connecto5|task-0] KafkaDatabaseHistory Producer config: {bootstrap.servers=localhost:9094, value.serializer=org.apache.kafka.common.serialization.StringSerializer, buffer.memory=1048576, retries=1, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=testdb-dbhistory, linger.ms=0, batch.size=32768, max.block.ms=10000, acks=1} (io.debezium.relational.history.KafkaDatabaseHistory:220)
[2022-11-11 20:03:07,952] INFO [CMS-connecto5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = db-history-config-check (io.debezium.util.Threads:270)
[2022-11-11 20:03:07,999] INFO [CMS-connecto5|task-0] Idempotence will be disabled because acks is set to 1, not set to 'all'. (org.apache.kafka.clients.producer.ProducerConfig:501)
[2022-11-11 20:03:08,010] INFO [CMS-connecto5|task-0] ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9094]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:376)
[2022-11-11 20:03:08,026] INFO [CMS-connecto5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:03:08,030] INFO [CMS-connecto5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:03:08,032] INFO [CMS-connecto5|task-0] Kafka startTimeMs: 1668193388026 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:03:08,033] INFO [CMS-connecto5|task-0] Closing connection before starting schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:96)
[2022-11-11 20:03:08,075] INFO [CMS-connecto5|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:965)
[2022-11-11 20:03:08,082] INFO [CMS-connecto5|task-0] [Producer clientId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:03:08,092] INFO [CMS-connecto5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:03:08,111] INFO [CMS-connecto5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:03:08,117] INFO [CMS-connecto5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:03:08,118] INFO [CMS-connecto5|task-0] Kafka startTimeMs: 1668193388111 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:03:08,133] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:03:08,145] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:03:08,146] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:03:08,147] INFO [CMS-connecto5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:03:08,148] INFO [CMS-connecto5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:03:08,149] INFO [CMS-connecto5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:03:08,150] INFO [CMS-connecto5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:03:08,158] INFO [CMS-connecto5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:03:08,195] INFO [CMS-connecto5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:03:08,195] INFO [CMS-connecto5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:03:08,197] INFO [CMS-connecto5|task-0] Kafka startTimeMs: 1668193388195 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:03:08,199] INFO [CMS-connecto5|task-0] Creating thread debezium-mysqlconnector-testdb-db-history-config-check (io.debezium.util.Threads:287)
[2022-11-11 20:03:08,209] INFO [CMS-connecto5|task-0] AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory-topic-check
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-11 20:03:08,211] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to Y5YhC3nSSyCom-dQQb7uYQ (org.apache.kafka.clients.Metadata:402)
[2022-11-11 20:03:08,219] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:03:08,217] WARN [CMS-connecto5|task-0] The configuration 'value.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,246] WARN [CMS-connecto5|task-0] The configuration 'batch.size' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,247] WARN [CMS-connecto5|task-0] The configuration 'max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,249] WARN [CMS-connecto5|task-0] The configuration 'acks' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,249] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:03:08,252] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:03:08,256] INFO [CMS-connecto5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:03:08,251] WARN [CMS-connecto5|task-0] The configuration 'buffer.memory' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,258] INFO [CMS-connecto5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:03:08,264] INFO [CMS-connecto5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:03:08,262] WARN [CMS-connecto5|task-0] The configuration 'key.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,269] INFO [CMS-connecto5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:03:08,278] INFO [CMS-connecto5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:03:08,275] WARN [CMS-connecto5|task-0] The configuration 'linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,297] INFO [CMS-connecto5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:03:08,306] INFO [CMS-connecto5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:03:08,307] INFO [CMS-connecto5|task-0] Kafka startTimeMs: 1668193388297 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:03:08,309] INFO [CMS-connecto5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:03:08,309] INFO [CMS-connecto5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:03:08,310] INFO [CMS-connecto5|task-0] Kafka startTimeMs: 1668193388301 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:03:08,316] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:03:08,331] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:03:08,331] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:03:08,333] INFO [CMS-connecto5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:03:08,334] INFO [CMS-connecto5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:03:08,335] INFO [CMS-connecto5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:03:08,338] INFO [CMS-connecto5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:03:08,339] INFO [CMS-connecto5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:03:08,348] INFO [CMS-connecto5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:03:08,349] INFO [CMS-connecto5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:03:08,349] INFO [CMS-connecto5|task-0] Kafka startTimeMs: 1668193388348 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:03:08,362] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to Y5YhC3nSSyCom-dQQb7uYQ (org.apache.kafka.clients.Metadata:402)
[2022-11-11 20:03:08,363] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:03:08,378] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:03:08,379] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:03:08,381] INFO [CMS-connecto5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:03:08,390] INFO [CMS-connecto5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:03:08,391] INFO [CMS-connecto5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:03:08,395] INFO [CMS-connecto5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:03:08,396] INFO [CMS-connecto5|task-0] Started database history recovery (io.debezium.relational.history.DatabaseHistoryMetrics:113)
[2022-11-11 20:03:08,398] INFO [CMS-connecto5|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testdb-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2022-11-11 20:03:08,410] INFO [CMS-connecto5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:03:08,412] INFO [CMS-connecto5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:03:08,415] INFO [CMS-connecto5|task-0] Kafka startTimeMs: 1668193388410 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:03:08,416] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Subscribed to topic(s): schema-changes.inventory (org.apache.kafka.clients.consumer.KafkaConsumer:968)
[2022-11-11 20:03:08,423] INFO [CMS-connecto5|task-0] Database history topic 'schema-changes.inventory' has correct settings (io.debezium.relational.history.KafkaDatabaseHistory:444)
[2022-11-11 20:03:08,429] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting the last seen epoch of partition schema-changes.inventory-0 to 0 since the associated topicId changed from null to Y5YhC3nSSyCom-dQQb7uYQ (org.apache.kafka.clients.Metadata:402)
[2022-11-11 20:03:08,429] INFO [CMS-connecto5|task-0] App info kafka.admin.client for testdb-dbhistory-topic-check unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:03:08,430] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Cluster ID: i6BrIp1ISg2w9s8XmqXJvg (org.apache.kafka.clients.Metadata:287)
[2022-11-11 20:03:08,433] INFO [CMS-connecto5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:03:08,436] INFO [CMS-connecto5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:03:08,436] INFO [CMS-connecto5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:03:08,441] INFO [CMS-connecto5|task-0] AdminClientConfig values: 
	bootstrap.servers = [localhost:9094]
	client.dns.lookup = use_all_dns_ips
	client.id = testdb-dbhistory-topic-check
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:376)
[2022-11-11 20:03:08,449] WARN [CMS-connecto5|task-0] The configuration 'value.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,465] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Discovered group coordinator localhost:9094 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:884)
[2022-11-11 20:03:08,471] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:553)
[2022-11-11 20:03:08,469] WARN [CMS-connecto5|task-0] The configuration 'batch.size' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,490] WARN [CMS-connecto5|task-0] The configuration 'max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,492] WARN [CMS-connecto5|task-0] The configuration 'acks' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,493] WARN [CMS-connecto5|task-0] The configuration 'buffer.memory' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,494] WARN [CMS-connecto5|task-0] The configuration 'key.serializer' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,496] WARN [CMS-connecto5|task-0] The configuration 'linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:384)
[2022-11-11 20:03:08,497] INFO [CMS-connecto5|task-0] Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-11-11 20:03:08,498] INFO [CMS-connecto5|task-0] Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-11-11 20:03:08,499] INFO [CMS-connecto5|task-0] Kafka startTimeMs: 1668193388497 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-11-11 20:03:08,512] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: need to re-join with the given member-id: testdb-dbhistory-26c297af-c6e1-43cd-91d3-d56c5d3c0bd0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:03:08,513] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:03:08,518] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:553)
[2022-11-11 20:03:08,564] INFO [CMS-connecto5|task-0] Database history topic 'schema-changes.inventory' has correct settings (io.debezium.relational.history.KafkaDatabaseHistory:444)
[2022-11-11 20:03:08,576] INFO [CMS-connecto5|task-0] App info kafka.admin.client for testdb-dbhistory-topic-check unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:03:08,594] INFO [CMS-connecto5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:03:08,597] INFO [CMS-connecto5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:03:08,598] INFO [CMS-connecto5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:03:08,610] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Successfully joined group with generation Generation{generationId=3, memberId='testdb-dbhistory-26c297af-c6e1-43cd-91d3-d56c5d3c0bd0', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:614)
[2022-11-11 20:03:08,611] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Finished assignment for group at generation 3: {testdb-dbhistory-26c297af-c6e1-43cd-91d3-d56c5d3c0bd0=Assignment(partitions=[schema-changes.inventory-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:702)
[2022-11-11 20:03:08,628] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Successfully synced group in generation Generation{generationId=3, memberId='testdb-dbhistory-26c297af-c6e1-43cd-91d3-d56c5d3c0bd0', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:789)
[2022-11-11 20:03:08,629] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Notifying assignor about the new Assignment(partitions=[schema-changes.inventory-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:301)
[2022-11-11 20:03:08,630] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Adding newly assigned partitions: schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:313)
[2022-11-11 20:03:08,634] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Found no committed offset for partition schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1515)
[2022-11-11 20:03:08,647] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting offset for partition schema-changes.inventory-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9094 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2022-11-11 20:03:11,183] INFO [CMS-connecto5|task-0] Database history recovery in progress, recovered 2 records (io.debezium.relational.history.DatabaseHistoryMetrics:127)
[2022-11-11 20:03:12,269] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Revoke previously assigned partitions schema-changes.inventory-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:332)
[2022-11-11 20:03:12,270] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Member testdb-dbhistory-26c297af-c6e1-43cd-91d3-d56c5d3c0bd0 sending LeaveGroup request to coordinator localhost:9094 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1111)
[2022-11-11 20:03:12,278] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1003)
[2022-11-11 20:03:12,280] INFO [CMS-connecto5|task-0] [Consumer clientId=testdb-dbhistory, groupId=testdb-dbhistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1050)
[2022-11-11 20:03:12,298] INFO [CMS-connecto5|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-11-11 20:03:12,298] INFO [CMS-connecto5|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-11-11 20:03:12,310] INFO [CMS-connecto5|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-11-11 20:03:12,324] INFO [CMS-connecto5|task-0] App info kafka.consumer for testdb-dbhistory unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-11-11 20:03:12,326] INFO [CMS-connecto5|task-0] Finished database history recovery of 36 change(s) in 3930 ms (io.debezium.relational.history.DatabaseHistoryMetrics:119)
[2022-11-11 20:03:12,437] INFO [CMS-connecto5|task-0] Reconnecting after finishing schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:110)
[2022-11-11 20:03:12,450] INFO [CMS-connecto5|task-0] Get all known binlogs from MySQL (io.debezium.connector.mysql.MySqlConnection:408)
[2022-11-11 20:03:12,456] INFO [CMS-connecto5|task-0] MySQL has the binlog file 'mysql-bin.000026' required by the connector (io.debezium.connector.mysql.MySqlConnectorTask:333)
[2022-11-11 20:03:12,463] INFO [CMS-connecto5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2022-11-11 20:03:12,467] INFO [CMS-connecto5|task-0] Creating thread debezium-mysqlconnector-testdb-change-event-source-coordinator (io.debezium.util.Threads:287)
[2022-11-11 20:03:12,469] INFO [CMS-connecto5|task-0] WorkerSourceTask{id=CMS-connecto5-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:227)
[2022-11-11 20:03:12,475] INFO [CMS-connecto5|task-0] WorkerSourceTask{id=CMS-connecto5-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2022-11-11 20:03:12,479] INFO [CMS-connecto5|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:102)
[2022-11-11 20:03:12,488] INFO [CMS-connecto5|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:105)
[2022-11-11 20:03:12,490] INFO [CMS-connecto5|task-0] A previous offset indicating a completed snapshot has been found. Neither schema nor data will be snapshotted. (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:82)
[2022-11-11 20:03:12,492] INFO [CMS-connecto5|task-0] Snapshot ended with SnapshotResult [status=SKIPPED, offset=MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000026, currentBinlogPosition=2887, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000026, restartBinlogPosition=2887, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]] (io.debezium.pipeline.ChangeEventSourceCoordinator:154)
[2022-11-11 20:03:12,494] INFO [CMS-connecto5|task-0] Requested thread factory for connector MySqlConnector, id = testdb named = binlog-client (io.debezium.util.Threads:270)
[2022-11-11 20:03:12,497] INFO [CMS-connecto5|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:171)
[2022-11-11 20:03:12,507] INFO [CMS-connecto5|task-0] Skip 2 events on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:914)
[2022-11-11 20:03:12,510] INFO [CMS-connecto5|task-0] Skip 1 rows on streaming start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:918)
[2022-11-11 20:03:12,512] INFO [CMS-connecto5|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-11 20:03:12,516] INFO [CMS-connecto5|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-11 20:03:12,531] INFO [CMS-connecto5|task-0] Connected to MySQL binlog at localhost:3306, starting at MySqlOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=SourceInfo [currentGtid=null, currentBinlogFilename=mysql-bin.000026, currentBinlogPosition=2887, currentRowNumber=0, serverId=0, sourceTime=null, threadId=-1, currentQuery=null, tableIds=[], databaseName=null], snapshotCompleted=false, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet=null, currentGtidSet=null, restartBinlogFilename=mysql-bin.000026, restartBinlogPosition=2887, restartRowsToSkip=1, restartEventsToSkip=2, currentEventLengthInBytes=0, inTransaction=false, transactionId=null, incrementalSnapshotContext =IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:1203)
[2022-11-11 20:03:12,533] INFO [CMS-connecto5|task-0] Waiting for keepalive thread to start (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:935)
[2022-11-11 20:03:12,534] INFO [CMS-connecto5|task-0] Creating thread debezium-mysqlconnector-testdb-binlog-client (io.debezium.util.Threads:287)
[2022-11-11 20:03:12,647] INFO [CMS-connecto5|task-0] Keepalive thread is running (io.debezium.connector.mysql.MySqlStreamingChangeEventSource:942)
[2022-11-11 20:12:07,843] INFO [CMS-connecto5|task-0] [Producer clientId=connector-producer-CMS-connecto5-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:935)
[2022-11-11 20:12:08,138] INFO [CMS-connecto5|task-0] [Producer clientId=testdb-dbhistory] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:935)
